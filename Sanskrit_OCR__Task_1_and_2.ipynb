{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "collapsed_sections": [
        "NW_F78Qi7Aez"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzcFNZ9RLbje",
        "outputId": "d373eb45-51a3-4a91-e220-edebc8bf220e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.11/dist-packages (1.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Collecting git+https://github.com/sanskrit-coders/chandas.git\n",
            "  Cloning https://github.com/sanskrit-coders/chandas.git to /tmp/pip-req-build-d_0_fxqh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/sanskrit-coders/chandas.git /tmp/pip-req-build-d_0_fxqh\n",
            "  Resolved https://github.com/sanskrit-coders/chandas.git to commit 2f715ebdc125060bbb75be4efcaef6a85bff23f2\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyICU in /usr/local/lib/python3.11/dist-packages (from chandas==0.0.10) (2.15.2)\n",
            "Requirement already satisfied: unicodecsv in /usr/local/lib/python3.11/dist-packages (from chandas==0.0.10) (0.14.1)\n",
            "Requirement already satisfied: indic_transliteration in /usr/local/lib/python3.11/dist-packages (from chandas==0.0.10) (2.3.69)\n",
            "Requirement already satisfied: backports.functools-lru-cache in /usr/local/lib/python3.11/dist-packages (from indic_transliteration->chandas==0.0.10) (2.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from indic_transliteration->chandas==0.0.10) (2024.11.6)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.11/dist-packages (from indic_transliteration->chandas==0.0.10) (0.15.3)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from indic_transliteration->chandas==0.0.10) (0.10.2)\n",
            "Requirement already satisfied: roman in /usr/local/lib/python3.11/dist-packages (from indic_transliteration->chandas==0.0.10) (5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic_transliteration->chandas==0.0.10) (8.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer->indic_transliteration->chandas==0.0.10) (4.13.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic_transliteration->chandas==0.0.10) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer->indic_transliteration->chandas==0.0.10) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->indic_transliteration->chandas==0.0.10) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer->indic_transliteration->chandas==0.0.10) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer->indic_transliteration->chandas==0.0.10) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium numpy pandas torch transformers\n",
        "!pip install git+https://github.com/sanskrit-coders/chandas.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "from gymnasium import spaces\n",
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ChandasEnvironment(gym.Env):\n",
        "    def __init__(self):\n",
        "        super(ChandasEnvironment, self).__init__()\n",
        "        self.action_space = spaces.Discrete(128)\n",
        "        self.observation_space = spaces.Dict({\n",
        "            'current_poem': spaces.Text(max_length=500),\n",
        "            'topic': spaces.Text(max_length=100),\n",
        "            'target_meter': spaces.Text(max_length=50)\n",
        "        })\n",
        "        self.meters = [\"anushtubh\", \"indravajra\", \"upendravajra\", \"rathoddhatā\", \"vasantatilakā\"]\n",
        "        self.topics = [\"nature\", \"devotion\", \"seasons\", \"philosophy\", \"love\"]\n",
        "        self.llm_grader_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        self.llm_grader_model = AutoModelForSequenceClassification.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "        self.max_length = 100\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        if seed is not None:\n",
        "            np.random.seed(seed)\n",
        "        self.target_meter = np.random.choice(self.meters)\n",
        "        self.topic = np.random.choice(self.topics)\n",
        "        self.current_poem = \"\"\n",
        "        self.length = 0\n",
        "        self.done = False\n",
        "        observation = {\n",
        "            'current_poem': self.current_poem,\n",
        "            'topic': self.topic,\n",
        "            'target_meter': self.target_meter\n",
        "        }\n",
        "        info = {}\n",
        "        return observation, info\n",
        "\n",
        "    def step(self, action):\n",
        "        char = chr(action)\n",
        "        self.current_poem += char\n",
        "        self.length += 1\n",
        "        if char == '।' or self.length >= self.max_length:\n",
        "            self.done = True\n",
        "        reward = self._calculate_reward()\n",
        "        observation = {\n",
        "            'current_poem': self.current_poem,\n",
        "            'topic': self.topic,\n",
        "            'target_meter': self.target_meter\n",
        "        }\n",
        "        info = {}\n",
        "        return observation, reward, self.done, False, info\n",
        "\n",
        "    def _calculate_reward(self):\n",
        "        if not self.done:\n",
        "            return 0\n",
        "        meter_score = self._verify_meter()\n",
        "        llm_score = self._llm_grader()\n",
        "        total_reward = meter_score + llm_score\n",
        "        return total_reward\n",
        "\n",
        "    def _verify_meter(self):\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                ['python', '-m', 'chandas', 'identify', '-', '--meter', self.target_meter],\n",
        "                input=self.current_poem,\n",
        "                capture_output=True, text=True, shell=True\n",
        "            )\n",
        "            if self.target_meter in result.stdout:\n",
        "                return 10.0\n",
        "            else:\n",
        "                return -1.0\n",
        "        except Exception as e:\n",
        "            print(f\"Error verifying meter: {e}\")\n",
        "            return -5.0\n",
        "\n",
        "    def _llm_grader(self):\n",
        "        inputs = self.llm_grader_tokenizer(self.current_poem, return_tensors=\"pt\")\n",
        "        outputs = self.llm_grader_model(**inputs)\n",
        "        logits = outputs.logits.detach().numpy()[0]\n",
        "        score = np.mean(logits)\n",
        "        reward = score * 5\n",
        "        return reward\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.softmax(x, dim=-1)\n",
        "\n",
        "def train_ppo(env, num_episodes=100):\n",
        "    input_dim = 100\n",
        "    output_dim = env.action_space.n\n",
        "    policy = PolicyNetwork(input_dim, output_dim)\n",
        "    optimizer = optim.Adam(policy.parameters(), lr=0.001)\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        done = False\n",
        "        rewards = []\n",
        "        log_probs = []\n",
        "\n",
        "        while not done:\n",
        "            features = torch.zeros(input_dim)\n",
        "            action_probs = policy(features)\n",
        "            dist = Categorical(action_probs)\n",
        "            action = dist.sample()\n",
        "            log_prob = dist.log_prob(action)\n",
        "            obs, reward, done, _, _ = env.step(action.item())\n",
        "            rewards.append(reward)\n",
        "            log_probs.append(log_prob)\n",
        "\n",
        "        returns = []\n",
        "        R = 0\n",
        "        for r in reversed(rewards):\n",
        "            R = r + 0.99 * R\n",
        "            returns.insert(0, R)\n",
        "\n",
        "        returns = torch.tensor(returns)\n",
        "        log_probs = torch.stack(log_probs)\n",
        "\n",
        "        loss = -(log_probs * returns).mean()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Episode {episode+1}, Reward: {sum(rewards)}')\n",
        "\n",
        "env = ChandasEnvironment()\n",
        "train_ppo(env)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db7r7JKkN9nE",
        "outputId": "19d3077c-0caa-4dee-ca47-9b61f6cd6482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Reward: -1.0885289907455444\n",
            "Episode 2, Reward: -1.085817813873291\n",
            "Episode 3, Reward: -1.1037017107009888\n",
            "Episode 4, Reward: -1.1035163402557373\n",
            "Episode 5, Reward: -1.1091465950012207\n",
            "Episode 6, Reward: -1.096011996269226\n",
            "Episode 7, Reward: -1.0947405099868774\n",
            "Episode 8, Reward: -1.1023616790771484\n",
            "Episode 9, Reward: -1.0667693614959717\n",
            "Episode 10, Reward: -1.0749965906143188\n",
            "Episode 11, Reward: -1.0290700197219849\n",
            "Episode 12, Reward: -1.115600347518921\n",
            "Episode 13, Reward: -1.0198194980621338\n",
            "Episode 14, Reward: -1.1253329515457153\n",
            "Episode 15, Reward: -1.0296404361724854\n",
            "Episode 16, Reward: -1.049535870552063\n",
            "Episode 17, Reward: -1.0078401565551758\n",
            "Episode 18, Reward: -1.1367676258087158\n",
            "Episode 19, Reward: -1.034040093421936\n",
            "Episode 20, Reward: -1.1011744737625122\n",
            "Episode 21, Reward: -1.081244945526123\n",
            "Episode 22, Reward: -1.0109505653381348\n",
            "Episode 23, Reward: -1.0158836841583252\n",
            "Episode 24, Reward: -1.1293070316314697\n",
            "Episode 25, Reward: -1.1111913919448853\n",
            "Episode 26, Reward: -1.045500636100769\n",
            "Episode 27, Reward: -1.0583443641662598\n",
            "Episode 28, Reward: -1.1071882247924805\n",
            "Episode 29, Reward: -1.0239304304122925\n",
            "Episode 30, Reward: -1.0606894493103027\n",
            "Episode 31, Reward: -1.0654457807540894\n",
            "Episode 32, Reward: -1.0536110401153564\n",
            "Episode 33, Reward: -1.0444854497909546\n",
            "Episode 34, Reward: -1.0734871625900269\n",
            "Episode 35, Reward: -1.1139531135559082\n",
            "Episode 36, Reward: -1.078371286392212\n",
            "Episode 37, Reward: -1.0791743993759155\n",
            "Episode 38, Reward: -1.0639342069625854\n",
            "Episode 39, Reward: -1.0857751369476318\n",
            "Episode 40, Reward: -1.106622338294983\n",
            "Episode 41, Reward: -1.002993106842041\n",
            "Episode 42, Reward: -1.0002413988113403\n",
            "Episode 43, Reward: -1.1510430574417114\n",
            "Episode 44, Reward: -1.026800513267517\n",
            "Episode 45, Reward: -1.0264171361923218\n",
            "Episode 46, Reward: -1.1145949363708496\n",
            "Episode 47, Reward: -1.0998257398605347\n",
            "Episode 48, Reward: -1.0348297357559204\n",
            "Episode 49, Reward: -1.0713547468185425\n",
            "Episode 50, Reward: -1.0958194732666016\n",
            "Episode 51, Reward: -1.0433419942855835\n",
            "Episode 52, Reward: -1.0493906736373901\n",
            "Episode 53, Reward: -1.0116333961486816\n",
            "Episode 54, Reward: -1.031381368637085\n",
            "Episode 55, Reward: -1.0529488325119019\n",
            "Episode 56, Reward: -1.0927311182022095\n",
            "Episode 57, Reward: -1.106479525566101\n",
            "Episode 58, Reward: -1.1072396039962769\n",
            "Episode 59, Reward: -1.0941983461380005\n",
            "Episode 60, Reward: -1.0647220611572266\n",
            "Episode 61, Reward: -1.0274631977081299\n",
            "Episode 62, Reward: -1.0881333351135254\n",
            "Episode 63, Reward: -1.0488139390945435\n",
            "Episode 64, Reward: -1.052828311920166\n",
            "Episode 65, Reward: -1.0675179958343506\n",
            "Episode 66, Reward: -1.0744051933288574\n",
            "Episode 67, Reward: -1.0588828325271606\n",
            "Episode 68, Reward: -1.0460395812988281\n",
            "Episode 69, Reward: -1.0836142301559448\n",
            "Episode 70, Reward: -1.0456175804138184\n",
            "Episode 71, Reward: -1.0975232124328613\n",
            "Episode 72, Reward: -1.087504267692566\n",
            "Episode 73, Reward: -1.0465607643127441\n",
            "Episode 74, Reward: -1.0323399305343628\n",
            "Episode 75, Reward: -1.1296091079711914\n",
            "Episode 76, Reward: -1.011777639389038\n",
            "Episode 77, Reward: -1.1072797775268555\n",
            "Episode 78, Reward: -1.0715793371200562\n",
            "Episode 79, Reward: -1.106964111328125\n",
            "Episode 80, Reward: -1.111615538597107\n",
            "Episode 81, Reward: -1.031309962272644\n",
            "Episode 82, Reward: -1.0470106601715088\n",
            "Episode 83, Reward: -1.0681499242782593\n",
            "Episode 84, Reward: -1.2092208862304688\n",
            "Episode 85, Reward: -1.0899009704589844\n",
            "Episode 86, Reward: -1.1313719749450684\n",
            "Episode 87, Reward: -1.0952303409576416\n",
            "Episode 88, Reward: -1.1097042560577393\n",
            "Episode 89, Reward: -1.0153491497039795\n",
            "Episode 90, Reward: -1.0711925029754639\n",
            "Episode 91, Reward: -1.0398523807525635\n",
            "Episode 92, Reward: -1.059268593788147\n",
            "Episode 93, Reward: -1.014945149421692\n",
            "Episode 94, Reward: -1.0711697340011597\n",
            "Episode 95, Reward: -1.094414472579956\n",
            "Episode 96, Reward: -1.0470072031021118\n",
            "Episode 97, Reward: -1.0951896905899048\n",
            "Episode 98, Reward: -1.0592021942138672\n",
            "Episode 99, Reward: -1.1400989294052124\n",
            "Episode 100, Reward: -1.0460408926010132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yDWVXJ2oPJ71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AAPGFBL9PJ-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pWMzcxCBPKA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Teb51QRPKDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sanskrit Metrical Poetry Generation**"
      ],
      "metadata": {
        "id": "RO6AL4H_P-_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Required imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import random\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "0bmJsedyZv_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "!pip install pandas\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2VYautPPKK1",
        "outputId": "0d1c0343-8206-45d9-ccee-5e4552a22950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"Qwen/Qwen3-0.6B\"  # or whatever model you’re using\n",
        "hf_token = \"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\"  # if needed\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_auth_token=hf_token)\n",
        "\n",
        "# Load causal LM model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    use_auth_token=hf_token,\n",
        "    torch_dtype=torch.float16,      # or torch.float32 / torch.bfloat16\n",
        "    device_map=\"auto\"               # optional, for automatic device placement\n",
        ")\n",
        "\n",
        "print(\"✅ Model and tokenizer loaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT0NRaaMPKXC",
        "outputId": "e14c0b7b-7fa9-4aee-f7c1-c107899d290f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Chandas verification utility\n",
        "# This implements checking for Sanskrit meter rules\n",
        "class ChandasVerifier:\n",
        "    def __init__(self):\n",
        "        # Dictionary of common Sanskrit meters and their patterns\n",
        "        # Each pattern is represented as a sequence of 'L' (laghu/short) and 'G' (guru/long) syllables\n",
        "        self.meter_patterns = {\n",
        "            'anushtup': ['L', 'G', 'L', 'G', 'L', 'G', 'L', 'G'] * 4,  # 8 syllables x 4 padas\n",
        "            'vasantatilaka': ['G', 'G', 'L', 'G', 'G', 'L', 'G', 'L', 'G', 'G', 'L', 'G', 'L', 'G'],\n",
        "            'mandakranta': ['G', 'G', 'G', 'G', 'L', 'G', 'L', 'L', 'G', 'L', 'G', 'G', 'L', 'G', 'L', 'G', 'G'],\n",
        "            'shardulvikridita': ['G', 'G', 'G', 'L', 'G', 'G', 'L', 'L', 'G', 'G', 'L', 'G', 'L', 'G', 'G', 'L', 'G', 'L', 'G'],\n",
        "            # Add more meters as needed\n",
        "        }\n",
        "\n",
        "        # Rules for determining if a syllable is laghu (short) or guru (long)\n",
        "        self.vowels = {'a', 'i', 'u', 'e', 'o', 'A', 'I', 'U', 'E', 'O', 'R', 'RR', 'L', 'LL'}\n",
        "        self.long_vowels = {'A', 'I', 'U', 'E', 'O', 'ai', 'au', 'RR', 'LL'}\n",
        "\n",
        "    def is_guru(self, syllable):\n",
        "        \"\"\"Determine if a syllable is guru (long)\"\"\"\n",
        "        # A syllable is guru if:\n",
        "        # 1. It contains a long vowel\n",
        "        # 2. Its vowel is followed by a conjunct consonant\n",
        "        # 3. Its vowel is followed by anusvara or visarga\n",
        "\n",
        "        for long_vowel in self.long_vowels:\n",
        "            if long_vowel in syllable:\n",
        "                return True\n",
        "\n",
        "        # Check for conjunct consonants (simplified)\n",
        "        if re.search(r'[aeiouAEIOU][^aeiouAEIOU]{2,}', syllable):\n",
        "            return True\n",
        "\n",
        "        # Check for anusvara (M) or visarga (H)\n",
        "        if 'M' in syllable or 'H' in syllable:\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "    def syllabify(self, text):\n",
        "        \"\"\"Split Sanskrit text into syllables (simplified implementation)\"\"\"\n",
        "        # This is a simplified syllabification - a full implementation would require\n",
        "        # more sophisticated Sanskrit processing\n",
        "        syllables = []\n",
        "        current = \"\"\n",
        "\n",
        "        for char in text:\n",
        "            current += char\n",
        "            if char in 'aeiouAEIOU':\n",
        "                syllables.append(current)\n",
        "                current = \"\"\n",
        "\n",
        "        # Add any remaining text\n",
        "        if current:\n",
        "            syllables.append(current)\n",
        "\n",
        "        return syllables\n",
        "\n",
        "    def get_metrical_pattern(self, text):\n",
        "        \"\"\"Convert text to a pattern of guru and laghu syllables\"\"\"\n",
        "        syllables = self.syllabify(text)\n",
        "        pattern = []\n",
        "\n",
        "        for syllable in syllables:\n",
        "            if self.is_guru(syllable):\n",
        "                pattern.append('G')\n",
        "            else:\n",
        "                pattern.append('L')\n",
        "\n",
        "        return pattern\n",
        "\n",
        "    def verify_meter(self, text, meter_name):\n",
        "        \"\"\"Check if text follows a specific metrical pattern\"\"\"\n",
        "        if meter_name not in self.meter_patterns:\n",
        "            raise ValueError(f\"Meter {meter_name} not found in the defined patterns\")\n",
        "\n",
        "        expected_pattern = self.meter_patterns[meter_name]\n",
        "        actual_pattern = self.get_metrical_pattern(text)\n",
        "\n",
        "        # Check if the patterns match\n",
        "        if len(actual_pattern) != len(expected_pattern):\n",
        "            return False\n",
        "\n",
        "        for i in range(len(actual_pattern)):\n",
        "            if actual_pattern[i] != expected_pattern[i]:\n",
        "                return False\n",
        "\n",
        "        return True"
      ],
      "metadata": {
        "id": "uNdyJC-7PKGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Dataset creation\n",
        "def create_sanskrit_poetry_dataset(topics, meters, size=100):\n",
        "    \"\"\"\n",
        "    Create a dataset of poetry tasks with topics and meter requirements\n",
        "\n",
        "    Args:\n",
        "        topics: List of potential topics\n",
        "        meters: List of meter names\n",
        "        size: Number of examples to generate\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with columns 'topic', 'meter', 'instructions'\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    for _ in range(size):\n",
        "        topic = random.choice(topics)\n",
        "        meter = random.choice(meters)\n",
        "\n",
        "        instructions = f\"Compose a Sanskrit poem on the topic '{topic}' following the '{meter}' meter.\"\n",
        "\n",
        "        data.append({\n",
        "            'topic': topic,\n",
        "            'meter': meter,\n",
        "            'instructions': instructions\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Example usage\n",
        "sanskrit_topics = [\n",
        "    \"nature\", \"love\", \"devotion\", \"seasons\", \"wisdom\",\n",
        "    \"courage\", \"victory\", \"peace\", \"knowledge\", \"beauty\"\n",
        "]\n",
        "\n",
        "sanskrit_meters = list(ChandasVerifier().meter_patterns.keys())\n",
        "\n",
        "poetry_dataset = create_sanskrit_poetry_dataset(sanskrit_topics, sanskrit_meters)"
      ],
      "metadata": {
        "id": "x1-5j8MJPKIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Model for Sanskrit poetry generation (Updated with Qwen model)\n",
        "class SanskritPoetryGenerator:\n",
        "    def __init__(self, model_name=\"Qwen/Qwen3-0.6B\"):\n",
        "        print(f\"Loading model: {model_name}\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "        self.verifier = ChandasVerifier()\n",
        "\n",
        "    def generate_poem(self, topic, meter, max_attempts=5):\n",
        "        \"\"\"\n",
        "        Generate a Sanskrit poem on a given topic following specified meter\n",
        "\n",
        "        Args:\n",
        "            topic: Topic for the poem\n",
        "            meter: Meter to follow\n",
        "            max_attempts: Maximum generation attempts to get correct meter\n",
        "\n",
        "        Returns:\n",
        "            Generated poem that follows the meter\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        Task: Write a Sanskrit poem about {topic} following the {meter} meter.\n",
        "\n",
        "        The {meter} meter has the following pattern of guru (G) and laghu (L) syllables:\n",
        "        {\"\".join(self.verifier.meter_patterns[meter])}\n",
        "\n",
        "        In Sanskrit, a syllable is guru (long) if it contains:\n",
        "        1. A long vowel (ā, ī, ū, etc.)\n",
        "        2. A short vowel followed by conjunct consonants\n",
        "        3. A short vowel followed by anusvara (ṃ) or visarga (ḥ)\n",
        "\n",
        "        All other syllables are laghu (short).\n",
        "\n",
        "        Please generate a beautiful Sanskrit poem on {topic} following this metrical pattern:\n",
        "        \"\"\"\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "            # Generate with some randomness for creativity\n",
        "            output = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_length=200,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                top_k=50,\n",
        "                top_p=0.95,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "            poem = self.tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract just the Sanskrit part (assuming model might output explanations)\n",
        "            sanskrit_lines = []\n",
        "            for line in poem.split('\\n'):\n",
        "                # Simplified check for Sanskrit text (contains Devanagari)\n",
        "                if re.search(r'[\\u0900-\\u097F]', line):\n",
        "                    sanskrit_lines.append(line)\n",
        "\n",
        "            if sanskrit_lines:\n",
        "                sanskrit_poem = '\\n'.join(sanskrit_lines)\n",
        "            else:\n",
        "                sanskrit_poem = poem  # Use full text if no Devanagari detected\n",
        "\n",
        "            # Verify if the poem follows the meter\n",
        "            if self.verifier.verify_meter(sanskrit_poem, meter):\n",
        "                return sanskrit_poem\n",
        "\n",
        "            # If not, refine the prompt for the next attempt\n",
        "            prompt = f\"\"\"\n",
        "            Your previous attempt didn't match the {meter} meter exactly.\n",
        "\n",
        "            Please try again with more attention to the syllable pattern:\n",
        "            {\"\".join(self.verifier.meter_patterns[meter])}\n",
        "\n",
        "            Write a Sanskrit poem about {topic} strictly following this meter pattern.\n",
        "            \"\"\"\n",
        "\n",
        "        # If we couldn't generate a valid poem after max attempts, return the last one with a warning\n",
        "        return f\"[Note: This poem may not strictly follow the {meter} meter]\\n{sanskrit_poem}\""
      ],
      "metadata": {
        "id": "bHJlWCsbQhUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. LLM Grader to prevent reward hacking\n",
        "class SanskritPoetryGrader:\n",
        "    def __init__(self, model_name=\"gpt-3.5-turbo\"):\n",
        "        # Use an API-based model for evaluation to prevent reward hacking\n",
        "        # This is a placeholder - you would need to implement the actual API call\n",
        "        self.model_name = model_name\n",
        "        self.verifier = ChandasVerifier()\n",
        "\n",
        "    def grade_poem(self, poem, topic, meter):\n",
        "        \"\"\"\n",
        "        Grade a Sanskrit poem based on meter correctness and topic relevance\n",
        "\n",
        "        Args:\n",
        "            poem: The Sanskrit poem to evaluate\n",
        "            topic: Expected topic\n",
        "            meter: Expected meter\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with scores and feedback\n",
        "        \"\"\"\n",
        "        # First check meter using the verifier\n",
        "        meter_correct = self.verifier.verify_meter(poem, meter)\n",
        "\n",
        "        # Create prompt for the LLM grader to evaluate content and quality\n",
        "        grading_prompt = f\"\"\"\n",
        "        Evaluate the following Sanskrit poem:\n",
        "\n",
        "        {poem}\n",
        "\n",
        "        The poem should be about: {topic}\n",
        "        The poem should follow the {meter} meter.\n",
        "\n",
        "        Please provide scores (1-10) for:\n",
        "        1. Topic relevance\n",
        "        2. Poetic quality\n",
        "        3. Cultural authenticity\n",
        "        4. Meter correctness (technical evaluation)\n",
        "\n",
        "        Also provide brief feedback.\n",
        "        \"\"\"\n",
        "\n",
        "        # This would be an API call to the evaluation model\n",
        "        # For now, we'll simulate a response\n",
        "\n",
        "        # Simulated API response\n",
        "        eval_scores = {\n",
        "            \"topic_relevance\": 8,\n",
        "            \"poetic_quality\": 7,\n",
        "            \"cultural_authenticity\": 8,\n",
        "            \"meter_correctness\": 10 if meter_correct else 4,\n",
        "            \"feedback\": \"The poem effectively addresses the topic and shows good understanding of Sanskrit poetic traditions.\",\n",
        "            \"overall_score\": 0  # Will be calculated\n",
        "        }\n",
        "\n",
        "        # Calculate overall score with meter correctness weighted heavily\n",
        "        eval_scores[\"overall_score\"] = (\n",
        "            eval_scores[\"topic_relevance\"] * 0.2 +\n",
        "            eval_scores[\"poetic_quality\"] * 0.2 +\n",
        "            eval_scores[\"cultural_authenticity\"] * 0.1 +\n",
        "            eval_scores[\"meter_correctness\"] * 0.5  # High weight for meter correctness\n",
        "        )\n",
        "\n",
        "        return eval_scores"
      ],
      "metadata": {
        "id": "w0N47OeeQarT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Training loop with RLHF (Reinforcement Learning from Human Feedback)\n",
        "from tqdm import tqdm  # Add this import at the top\n",
        "\n",
        "def train_with_rlhf(generator, grader, dataset, epochs=3, learning_rate=5e-5):\n",
        "    \"\"\"\n",
        "    Train the poetry generator using RLHF approach\n",
        "\n",
        "    Args:\n",
        "        generator: SanskritPoetryGenerator instance\n",
        "        grader: SanskritPoetryGrader instance\n",
        "        dataset: DataFrame with poetry tasks\n",
        "        epochs: Number of training epochs\n",
        "        learning_rate: Learning rate for model updates\n",
        "    \"\"\"\n",
        "    # Setup optimizer\n",
        "    optimizer = torch.optim.AdamW(generator.model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_reward = 0\n",
        "\n",
        "        for idx, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
        "            topic = row['topic']\n",
        "            meter = row['meter']\n",
        "\n",
        "            # Generate poem\n",
        "            poem = generator.generate_poem(topic, meter)\n",
        "\n",
        "            # Get feedback from grader\n",
        "            evaluation = grader.grade_poem(poem, topic, meter)\n",
        "            reward = evaluation[\"overall_score\"]\n",
        "            total_reward += reward\n",
        "\n",
        "            # Convert to tensor for backpropagation\n",
        "            reward_tensor = torch.tensor(reward, requires_grad=True)\n",
        "\n",
        "            # Compute loss (negative reward to minimize)\n",
        "            loss = -reward_tensor\n",
        "\n",
        "            # Backpropagate\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Report progress\n",
        "        avg_reward = total_reward / len(dataset)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Average Reward: {avg_reward:.4f}\")\n",
        "\n",
        "    # Save the trained model\n",
        "    generator.model.save_pretrained(\"./sanskrit_poetry_generator\")\n",
        "    generator.tokenizer.save_pretrained(\"./sanskrit_poetry_generator\")\n",
        "\n",
        "    return generator"
      ],
      "metadata": {
        "id": "4Nod7j7UPKNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Main execution script\n",
        "def main():\n",
        "    # Initialize components\n",
        "    verifier = ChandasVerifier()\n",
        "\n",
        "    # Create dataset\n",
        "    sanskrit_topics = [\n",
        "        \"nature\", \"love\", \"devotion\", \"seasons\", \"wisdom\",\n",
        "        \"courage\", \"victory\", \"peace\", \"knowledge\", \"beauty\"\n",
        "    ]\n",
        "    sanskrit_meters = list(verifier.meter_patterns.keys())\n",
        "    poetry_dataset = create_sanskrit_poetry_dataset(sanskrit_topics, sanskrit_meters)\n",
        "\n",
        "    # Save dataset for future use\n",
        "    poetry_dataset.to_csv(\"sanskrit_poetry_tasks.csv\", index=False)\n",
        "\n",
        "    # Initialize models\n",
        "    generator = SanskritPoetryGenerator()\n",
        "    grader = SanskritPoetryGrader()\n",
        "\n",
        "    # Train the model\n",
        "    trained_generator = train_with_rlhf(generator, grader, poetry_dataset)\n",
        "\n",
        "    # Generate example poems\n",
        "    print(\"Generating example poems with the trained model:\")\n",
        "    for meter in sanskrit_meters[:3]:  # Generate examples for first 3 meters\n",
        "        poem = trained_generator.generate_poem(\"spring\", meter)\n",
        "        print(f\"\\nPoem in {meter} meter about spring:\")\n",
        "        print(poem)\n",
        "\n",
        "        # Evaluate the poem\n",
        "        evaluation = grader.grade_poem(poem, \"spring\", meter)\n",
        "        print(f\"Evaluation scores: {evaluation}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edibVCE5PKPx",
        "outputId": "3f29abce-be49-4b48-c07d-e6dfd3677a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model: Qwen/Qwen3-0.6B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 28/100 [3:23:51<8:46:14, 438.53s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Web interface for demonstration (using Streamlit)\n",
        "# Save this as app.py\n",
        "import streamlit as st\n",
        "from sanskrit_poetry import SanskritPoetryGenerator, ChandasVerifier, SanskritPoetryGrader\n",
        "\n",
        "def app():\n",
        "    st.title(\"Sanskrit Metrical Poetry Generator\")\n",
        "\n",
        "    # Load models\n",
        "    generator = SanskritPoetryGenerator(\"./sanskrit_poetry_generator\")\n",
        "    verifier = ChandasVerifier()\n",
        "    grader = SanskritPoetryGrader()\n",
        "\n",
        "    # User inputs\n",
        "    topic = st.text_input(\"Enter a topic for the poem:\", \"nature\")\n",
        "\n",
        "    meters = list(verifier.meter_patterns.keys())\n",
        "    meter = st.selectbox(\"Select a meter:\", meters)\n",
        "\n",
        "    if st.button(\"Generate Poem\"):\n",
        "        with st.spinner(\"Generating poem...\"):\n",
        "            poem = generator.generate_poem(topic, meter)\n",
        "\n",
        "        st.subheader(\"Generated Poem\")\n",
        "        st.text(poem)\n",
        "\n",
        "        # Check meter\n",
        "        is_correct = verifier.verify_meter(poem, meter)\n",
        "        if is_correct:\n",
        "            st.success(f\"✓ The poem correctly follows the {meter} meter!\")\n",
        "        else:\n",
        "            st.error(f\"✗ The poem does not strictly follow the {meter} meter.\")\n",
        "\n",
        "        # Show evaluation\n",
        "        with st.expander(\"See detailed evaluation\"):\n",
        "            evaluation = grader.grade_poem(poem, topic, meter)\n",
        "            st.json(evaluation)\n",
        "\n",
        "        # Display meter pattern\n",
        "        with st.expander(\"See meter pattern\"):\n",
        "            st.write(\"Expected pattern:\", \"\".join(verifier.meter_patterns[meter]))\n",
        "            actual_pattern = \"\".join(verifier.get_metrical_pattern(poem))\n",
        "            st.write(\"Actual pattern:\", actual_pattern)\n",
        "\n",
        "    # Add educational information\n",
        "    with st.sidebar:\n",
        "        st.subheader(\"About Sanskrit Meters\")\n",
        "        st.write(\"\"\"\n",
        "        Sanskrit poetry follows strict metrical rules called 'chandas'.\n",
        "        Each meter has a specific pattern of guru (long) and laghu (short) syllables.\n",
        "\n",
        "        - A syllable with a long vowel (ā, ī, ū, etc.) is guru\n",
        "        - A syllable with a short vowel followed by conjunct consonants is guru\n",
        "        - A syllable with anusvara or visarga is guru\n",
        "        - All other syllables are laghu\n",
        "        \"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app()"
      ],
      "metadata": {
        "id": "bUsO_HZbPKZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ffFjwLz_0LQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ceo21V10LTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l-kFyioh0LV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B-cEp5PS0LYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code for Sanskrit Morphological Processing with Paninian Grammar**"
      ],
      "metadata": {
        "id": "3UqsMWep1D7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Dataset Generation: Random Dhatus with Parameters"
      ],
      "metadata": {
        "id": "RUe8Xd531LTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Sample data - in a real implementation, use comprehensive lists\n",
        "SAMPLE_DHATUS = [\"भू\", \"कृ\", \"गम्\", \"पठ्\", \"वद्\", \"अस्\", \"दृश्\", \"ज्ञा\", \"स्था\", \"पा\"]\n",
        "GANAS = [\"भ्वादि\", \"अदादि\", \"जुहोत्यादि\", \"दिवादि\", \"स्वादि\", \"तुदादि\", \"रुधादि\", \"तनादि\", \"क्र्यादि\", \"चुरादि\"]\n",
        "PADAS = [\"परस्मैपद\", \"आत्मनेपद\", \"उभयपद\"]\n",
        "LAKARA = [\"लट्\", \"लिट्\", \"लुट्\", \"लृट्\", \"लोट्\", \"लङ्\", \"विधिलिङ्\", \"आशीर्लिङ्\", \"लुङ्\", \"लृङ्\"]\n",
        "PURUSHAS = [\"प्रथम\", \"मध्यम\", \"उत्तम\"]\n",
        "VACANAS = [\"एकवचन\", \"द्विवचन\", \"बहुवचन\"]\n",
        "\n",
        "def generate_random_dhatu_params(n_samples: int = 100) -> List[Dict]:\n",
        "    \"\"\"Generate random dhatus with morphological parameters.\"\"\"\n",
        "    samples = []\n",
        "    for _ in range(n_samples):\n",
        "        dhatu = random.choice(SAMPLE_DHATUS)\n",
        "        params = {\n",
        "            \"dhatu\": dhatu,\n",
        "            \"gana\": random.choice(GANAS),\n",
        "            \"pada\": random.choice(PADAS),\n",
        "            \"lakara\": random.choice(LAKARA),\n",
        "            \"purusha\": random.choice(PURUSHAS),\n",
        "            \"vacana\": random.choice(VACANAS)\n",
        "        }\n",
        "        samples.append(params)\n",
        "    return samples\n",
        "\n",
        "# Generate and save dataset\n",
        "dhatu_dataset = generate_random_dhatu_params(1000)\n",
        "with open(\"dhatu_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dhatu_dataset, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Generated dataset with {len(dhatu_dataset)} dhatu samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMqdbzCK0LbO",
        "outputId": "ed750f2a-ca15-4fc0-a09a-d1e5e4d13a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated dataset with 1000 dhatu samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hOEh6-891Kmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Integration with Vidyut-Prakriya for Verification"
      ],
      "metadata": {
        "id": "U7Mp2UBS2DLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from typing import Dict, Optional\n",
        "\n",
        "class VidyutPrakriyaClient:\n",
        "    \"\"\"Client for interacting with Vidyut-Prakriya API for Sanskrit morphological generation.\"\"\"\n",
        "\n",
        "    def __init__(self, api_url: str = \"https://api.sanskritworld.org/v1/prakriya\"):\n",
        "        self.api_url = api_url\n",
        "\n",
        "    def get_surface_form(self, params: Dict) -> Optional[str]:\n",
        "        \"\"\"\n",
        "        Get the surface form of a verb by querying Vidyut-Prakriya.\n",
        "\n",
        "        Args:\n",
        "            params: Dictionary with dhatu and grammatical parameters\n",
        "\n",
        "        Returns:\n",
        "            Surface form or None if generation failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            payload = {\n",
        "                \"dhatu\": params[\"dhatu\"],\n",
        "                \"gana\": params[\"gana\"],\n",
        "                \"pada\": params[\"pada\"],\n",
        "                \"lakara\": params[\"lakara\"],\n",
        "                \"purusha\": params[\"purusha\"],\n",
        "                \"vacana\": params[\"vacana\"]\n",
        "            }\n",
        "\n",
        "            response = requests.post(self.api_url, json=payload)\n",
        "            if response.status_code == 200:\n",
        "                result = response.json()\n",
        "                return result.get(\"surface_form\")\n",
        "            else:\n",
        "                print(f\"API error: {response.status_code}, {response.text}\")\n",
        "                return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error calling Vidyut-Prakriya: {e}\")\n",
        "            return None\n",
        "\n",
        "# Example usage\n",
        "prakriya_client = VidyutPrakriyaClient()\n",
        "sample_params = {\n",
        "    \"dhatu\": \"भू\",\n",
        "    \"gana\": \"भ्वादि\",\n",
        "    \"pada\": \"परस्मैपद\",\n",
        "    \"lakara\": \"लट्\",\n",
        "    \"purusha\": \"प्रथम\",\n",
        "    \"vacana\": \"एकवचन\"\n",
        "}\n",
        "\n",
        "surface_form = prakriya_client.get_surface_form(sample_params)\n",
        "print(f\"Dhatu: {sample_params['dhatu']}, Surface form: {surface_form}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwcVu9ht0Ldh",
        "outputId": "912162c3-e804-4dde-8860-2147584dc355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error calling Vidyut-Prakriya: HTTPSConnectionPool(host='api.sanskritworld.org', port=443): Max retries exceeded with url: /v1/prakriya (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x7a3955de0b10>: Failed to resolve 'api.sanskritworld.org' ([Errno -2] Name or service not known)\"))\n",
            "Dhatu: भू, Surface form: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the library first\n",
        "!pip install vidyut-prakriya\n",
        "\n",
        "# Then use it directly\n",
        "from vidyut_prakriya.generator import Generator\n",
        "\n",
        "class VidyutPrakriyaClient:\n",
        "    \"\"\"Client for using Vidyut-Prakriya for Sanskrit morphological generation.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.generator = Generator()\n",
        "\n",
        "    def get_surface_form(self, params: dict) -> str:\n",
        "        \"\"\"\n",
        "        Get the surface form of a verb using Vidyut-Prakriya.\n",
        "\n",
        "        Args:\n",
        "            params: Dictionary with dhatu and grammatical parameters\n",
        "\n",
        "        Returns:\n",
        "            Surface form or None if generation failed\n",
        "        \"\"\"\n",
        "        try:\n",
        "            results = self.generator.generate(\n",
        "                vidyut_prakriya.Params(\n",
        "                    dhatu=params[\"dhatu\"],\n",
        "                    gana=params[\"gana\"],\n",
        "                    pada=params[\"pada\"],\n",
        "                    lakara=params[\"lakara\"],\n",
        "                    purusha=params[\"purusha\"],\n",
        "                    vacana=params[\"vacana\"]\n",
        "                )\n",
        "            )\n",
        "\n",
        "            if results and len(results) > 0:\n",
        "                # Return the first surface form\n",
        "                return results[0].text\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error using Vidyut-Prakriya: {e}\")\n",
        "            return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "dNxXa7qT0Lf9",
        "outputId": "90d0c2c4-011a-40aa-bfc9-c3a6ab947dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement vidyut-prakriya (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for vidyut-prakriya\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'vidyut_prakriya'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-790338e71095>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Then use it directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mvidyut_prakriya\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVidyutPrakriyaClient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'vidyut_prakriya'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplePaniniRules:\n",
        "    \"\"\"A simplified implementation of Paninian morphology rules for Sanskrit verb conjugation.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define basic terminations for लट् (present tense)\n",
        "        self.lat_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ति\", \"द्विवचन\": \"तः\", \"बहुवचन\": \"अन्ति\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"सि\", \"द्विवचन\": \"थः\", \"बहुवचन\": \"थ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"मि\", \"द्विवचन\": \"वः\", \"बहुवचन\": \"मः\"}\n",
        "            },\n",
        "            \"आत्मनेपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ते\", \"द्विवचन\": \"आते\", \"बहुवचन\": \"अन्ते\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"से\", \"द्विवचन\": \"एथे\", \"बहुवचन\": \"ध्वे\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"ए\", \"द्विवचन\": \"वहे\", \"बहुवचन\": \"महे\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Rules for verb stem formation based on dhatu and gana\n",
        "        self.stem_rules = {\n",
        "            \"भू\": {\"भ्वादि\": \"भव\"},\n",
        "            \"कृ\": {\"तनादि\": \"कर\", \"क्र्यादि\": \"कुरु\"},\n",
        "            \"गम्\": {\"भ्वादि\": \"गच्छ\"},\n",
        "            \"पठ्\": {\"भ्वादि\": \"पठ\"},\n",
        "            \"वद्\": {\"भ्वादि\": \"वद\"},\n",
        "            \"अस्\": {\"अदादि\": \"अस्\"},\n",
        "            \"दृश्\": {\"अदादि\": \"पश्य\"},\n",
        "            \"ज्ञा\": {\"क्र्यादि\": \"जान\"},\n",
        "            \"स्था\": {\"भ्वादि\": \"तिष्ठ\"},\n",
        "            \"पा\": {\"अदादि\": \"पिब\"}\n",
        "        }\n",
        "\n",
        "        # Simple rules for लिट् (perfect) tense\n",
        "        self.lit_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"आम\", \"द्विवचन\": \"अतुः\", \"बहुवचन\": \"उः\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"इथ\", \"द्विवचन\": \"अथुः\", \"बहुवचन\": \"अ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"अ\", \"द्विवचन\": \"इव\", \"बहुवचन\": \"इम\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Simple rules for लृट् (future) tense\n",
        "        self.lrt_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"स्यति\", \"द्विवचन\": \"स्यतः\", \"बहुवचन\": \"स्यन्ति\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"स्यसि\", \"द्विवचन\": \"स्यथः\", \"बहुवचन\": \"स्यथ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"स्यामि\", \"द्विवचन\": \"स्यावः\", \"बहुवचन\": \"स्यामः\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def get_surface_form(self, params):\n",
        "        \"\"\"Generate surface form using simplified Paninian rules.\"\"\"\n",
        "        dhatu = params[\"dhatu\"]\n",
        "        gana = params[\"gana\"]\n",
        "        pada = params[\"pada\"]\n",
        "        lakara = params[\"lakara\"]\n",
        "        purusha = params[\"purusha\"]\n",
        "        vacana = params[\"vacana\"]\n",
        "\n",
        "        # Get the appropriate verb stem based on dhatu and gana\n",
        "        if dhatu in self.stem_rules and gana in self.stem_rules[dhatu]:\n",
        "            stem = self.stem_rules[dhatu][gana]\n",
        "        else:\n",
        "            # Default stem formation for demonstration\n",
        "            stem = dhatu[:-1] if dhatu.endswith('्') else dhatu\n",
        "\n",
        "        # Apply terminations based on tense (lakara)\n",
        "        if lakara == \"लट्\":  # Present tense\n",
        "            if pada in self.lat_terminations and purusha in self.lat_terminations[pada]:\n",
        "                if vacana in self.lat_terminations[pada][purusha]:\n",
        "                    termination = self.lat_terminations[pada][purusha][vacana]\n",
        "                    return stem + termination\n",
        "\n",
        "        elif lakara == \"लिट्\":  # Perfect tense\n",
        "            if pada in self.lit_terminations and purusha in self.lit_terminations[pada]:\n",
        "                if vacana in self.lit_terminations[pada][purusha]:\n",
        "                    # For perfect, use a simplified reduplication\n",
        "                    redup = dhatu[0] + \"a\"\n",
        "                    termination = self.lit_terminations[pada][purusha][vacana]\n",
        "                    return redup + stem + termination\n",
        "\n",
        "        elif lakara == \"लृट्\":  # Future tense\n",
        "            if pada in self.lrt_terminations and purusha in self.lrt_terminations[pada]:\n",
        "                if vacana in self.lrt_terminations[pada][purusha]:\n",
        "                    termination = self.lrt_terminations[pada][purusha][vacana]\n",
        "                    return stem + termination\n",
        "\n",
        "        # For other tenses, return a placeholder\n",
        "        return f\"{stem}+{lakara}+{purusha}+{vacana}\""
      ],
      "metadata": {
        "id": "doqPuvag2yV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and test our simple rule-based implementation\n",
        "rule_engine = SimplePaniniRules()\n",
        "\n",
        "# Test with different parameters\n",
        "test_cases = [\n",
        "    {\n",
        "        \"dhatu\": \"भू\",\n",
        "        \"gana\": \"भ्वादि\",\n",
        "        \"pada\": \"परस्मैपद\",\n",
        "        \"lakara\": \"लट्\",\n",
        "        \"purusha\": \"प्रथम\",\n",
        "        \"vacana\": \"एकवचन\"\n",
        "    },\n",
        "    {\n",
        "        \"dhatu\": \"गम्\",\n",
        "        \"gana\": \"भ्वादि\",\n",
        "        \"pada\": \"परस्मैपद\",\n",
        "        \"lakara\": \"लट्\",\n",
        "        \"purusha\": \"प्रथम\",\n",
        "        \"vacana\": \"बहुवचन\"\n",
        "    },\n",
        "    {\n",
        "        \"dhatu\": \"कृ\",\n",
        "        \"gana\": \"तनादि\",\n",
        "        \"pada\": \"आत्मनेपद\",\n",
        "        \"lakara\": \"लट्\",\n",
        "        \"purusha\": \"मध्यम\",\n",
        "        \"vacana\": \"एकवचन\"\n",
        "    }\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    result = rule_engine.get_surface_form(case)\n",
        "    print(f\"Dhatu: {case['dhatu']}, Parameters: {case['lakara']} {case['purusha']} {case['vacana']}\")\n",
        "    print(f\"Surface form: {result}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3z2K0qF2yYN",
        "outputId": "6710de2f-1ce1-40a8-a380-49f185c6fdf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dhatu: भू, Parameters: लट् प्रथम एकवचन\n",
            "Surface form: भवति\n",
            "\n",
            "Dhatu: गम्, Parameters: लट् प्रथम बहुवचन\n",
            "Surface form: गच्छअन्ति\n",
            "\n",
            "Dhatu: कृ, Parameters: लट् मध्यम एकवचन\n",
            "Surface form: करसे\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_with_surface_forms(dhatu_dataset, rule_engine):\n",
        "    \"\"\"Create dataset with dhatu parameters and corresponding surface forms.\"\"\"\n",
        "    dataset_with_surface = []\n",
        "\n",
        "    for item in dhatu_dataset:\n",
        "        surface_form = rule_engine.get_surface_form(item)\n",
        "        if surface_form:\n",
        "            item[\"surface_form\"] = surface_form\n",
        "            dataset_with_surface.append(item)\n",
        "\n",
        "    return dataset_with_surface\n",
        "\n",
        "# Generate the dataset with surface forms\n",
        "rule_engine = SimplePaniniRules()\n",
        "dataset_with_surface = create_dataset_with_surface_forms(dhatu_dataset, rule_engine)\n",
        "\n",
        "# Save the dataset\n",
        "with open(\"dhatu_dataset_with_surface_forms.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dataset_with_surface, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Created dataset with {len(dataset_with_surface)} items with surface forms\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GhcEjIp3Vox",
        "outputId": "b9ade9ff-4efe-4d69-fb27-631a205c506b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset with 1000 items with surface forms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRltm_Fl3Zx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SimplePaniniRules:\n",
        "    \"\"\"A simplified implementation of Paninian morphology rules for Sanskrit verb conjugation.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define basic terminations for लट् (present tense)\n",
        "        self.lat_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ति\", \"द्विवचन\": \"तः\", \"बहुवचन\": \"अन्ति\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"सि\", \"द्विवचन\": \"थः\", \"बहुवचन\": \"थ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"मि\", \"द्विवचन\": \"वः\", \"बहुवचन\": \"मः\"}\n",
        "            },\n",
        "            \"आत्मनेपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ते\", \"द्विवचन\": \"आते\", \"बहुवचन\": \"अन्ते\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"से\", \"द्विवचन\": \"एथे\", \"बहुवचन\": \"ध्वे\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"ए\", \"द्विवचन\": \"वहे\", \"बहुवचन\": \"महे\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Rules for verb stem formation based on dhatu and gana\n",
        "        self.stem_rules = {\n",
        "            \"भू\": {\"भ्वादि\": \"भव\"},\n",
        "            \"कृ\": {\"तनादि\": \"कर\", \"क्र्यादि\": \"कुरु\"},\n",
        "            \"गम्\": {\"भ्वादि\": \"गच्छ\"},\n",
        "            \"पठ्\": {\"भ्वादि\": \"पठ\"},\n",
        "            \"वद्\": {\"भ्वादि\": \"वद\"},\n",
        "            \"अस्\": {\"अदादि\": \"अस्\"},\n",
        "            \"दृश्\": {\"अदादि\": \"पश्य\"},\n",
        "            \"ज्ञा\": {\"क्र्यादि\": \"जान\"},\n",
        "            \"स्था\": {\"भ्वादि\": \"तिष्ठ\"},\n",
        "            \"पा\": {\"अदादि\": \"पिब\"}\n",
        "        }\n",
        "\n",
        "        # Simple rules for लिट् (perfect) tense\n",
        "        self.lit_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"आम\", \"द्विवचन\": \"अतुः\", \"बहुवचन\": \"उः\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"इथ\", \"द्विवचन\": \"अथुः\", \"बहुवचन\": \"अ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"अ\", \"द्विवचन\": \"इव\", \"बहुवचन\": \"इम\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Simple rules for लृट् (future) tense\n",
        "        self.lrt_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"स्यति\", \"द्विवचन\": \"स्यतः\", \"बहुवचन\": \"स्यन्ति\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"स्यसि\", \"द्विवचन\": \"स्यथः\", \"बहुवचन\": \"स्यथ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"स्यामि\", \"द्विवचन\": \"स्यावः\", \"बहुवचन\": \"स्यामः\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def get_surface_form(self, params):\n",
        "        \"\"\"Generate surface form using simplified Paninian rules.\"\"\"\n",
        "        dhatu = params[\"dhatu\"]\n",
        "        gana = params[\"gana\"]\n",
        "        pada = params[\"pada\"]\n",
        "        lakara = params[\"lakara\"]\n",
        "        purusha = params[\"purusha\"]\n",
        "        vacana = params[\"vacana\"]\n",
        "\n",
        "        # Get the appropriate verb stem based on dhatu and gana\n",
        "        if dhatu in self.stem_rules and gana in self.stem_rules[dhatu]:\n",
        "            stem = self.stem_rules[dhatu][gana]\n",
        "        else:\n",
        "            # Default stem formation for demonstration\n",
        "            stem = dhatu[:-1] if dhatu.endswith('्') else dhatu\n",
        "\n",
        "        # Apply terminations based on tense (lakara)\n",
        "        if lakara == \"लट्\":  # Present tense\n",
        "            if pada in self.lat_terminations and purusha in self.lat_terminations[pada]:\n",
        "                if vacana in self.lat_terminations[pada][purusha]:\n",
        "                    termination = self.lat_terminations[pada][purusha][vacana]\n",
        "                    return stem + termination\n",
        "\n",
        "        elif lakara == \"लिट्\":  # Perfect tense\n",
        "            if pada in self.lit_terminations and purusha in self.lit_terminations[pada]:\n",
        "                if vacana in self.lit_terminations[pada][purusha]:\n",
        "                    # For perfect, use a simplified reduplication\n",
        "                    redup = dhatu[0] + \"a\"\n",
        "                    termination = self.lit_terminations[pada][purusha][vacana]\n",
        "                    return redup + stem + termination\n",
        "\n",
        "        elif lakara == \"लृट्\":  # Future tense\n",
        "            if pada in self.lrt_terminations and purusha in self.lrt_terminations[pada]:\n",
        "                if vacana in self.lrt_terminations[pada][purusha]:\n",
        "                    termination = self.lrt_terminations[pada][purusha][vacana]\n",
        "                    return stem + termination\n",
        "\n",
        "        # For other tenses, create a simple concatenation\n",
        "        return f\"{stem}+{lakara}+{purusha}+{vacana}\""
      ],
      "metadata": {
        "id": "o3A3tZUG3Z0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WaGCRpFC3Z2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_with_surface_forms(rule_engine):\n",
        "    \"\"\"Create dataset with dhatu parameters and corresponding surface forms.\"\"\"\n",
        "    # First, load the existing dataset if it exists\n",
        "    try:\n",
        "        with open(\"dhatu_dataset.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "            dhatu_dataset = json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        # If it doesn't exist, generate a new one\n",
        "        dhatu_dataset = generate_random_dhatu_params(1000)\n",
        "\n",
        "    dataset_with_surface = []\n",
        "\n",
        "    for item in dhatu_dataset:\n",
        "        surface_form = rule_engine.get_surface_form(item)\n",
        "        if surface_form:\n",
        "            item[\"surface_form\"] = surface_form\n",
        "            dataset_with_surface.append(item)\n",
        "\n",
        "    # Save the dataset\n",
        "    with open(\"dhatu_dataset_with_surface_forms.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(dataset_with_surface, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"Created dataset with {len(dataset_with_surface)} items with surface forms\")\n",
        "    return dataset_with_surface"
      ],
      "metadata": {
        "id": "hvHU6w2q4owS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g22GZLOo4oyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_char_mappings(dataset):\n",
        "    \"\"\"Create character-level vocabulary mappings.\"\"\"\n",
        "    all_chars = set()\n",
        "\n",
        "    # Collect characters from dhatus and surface forms\n",
        "    for item in dataset:\n",
        "        all_chars.update(item[\"dhatu\"])\n",
        "        all_chars.update(item[\"surface_form\"])\n",
        "\n",
        "    # Add special tokens\n",
        "    all_chars.update([\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"])\n",
        "\n",
        "    # Create mappings\n",
        "    char_to_idx = {char: idx for idx, char in enumerate(sorted(all_chars))}\n",
        "    idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "\n",
        "    return char_to_idx, idx_to_char\n",
        "\n",
        "class SanskritMorphologyDataset(Dataset):\n",
        "    \"\"\"Dataset for Sanskrit morphological transformations.\"\"\"\n",
        "\n",
        "    def __init__(self, data, char_to_idx, max_len=50):\n",
        "        self.data = data\n",
        "        self.char_to_idx = char_to_idx\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Map categorical features to indices\n",
        "        self.ganas = sorted(set(item[\"gana\"] for item in data))\n",
        "        self.padas = sorted(set(item[\"pada\"] for item in data))\n",
        "        self.lakaras = sorted(set(item[\"lakara\"] for item in data))\n",
        "        self.purushas = sorted(set(item[\"purusha\"] for item in data))\n",
        "        self.vacanas = sorted(set(item[\"vacana\"] for item in data))\n",
        "\n",
        "        self.gana_to_idx = {gana: idx for idx, gana in enumerate(self.ganas)}\n",
        "        self.pada_to_idx = {pada: idx for idx, pada in enumerate(self.padas)}\n",
        "        self.lakara_to_idx = {lakara: idx for idx, lakara in enumerate(self.lakaras)}\n",
        "        self.purusha_to_idx = {purusha: idx for idx, purusha in enumerate(self.purushas)}\n",
        "        self.vacana_to_idx = {vacana: idx for idx, vacana in enumerate(self.vacanas)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        # Encode dhatu\n",
        "        dhatu = item[\"dhatu\"]\n",
        "        dhatu_encoded = [self.char_to_idx.get(c, self.char_to_idx[\"<UNK>\"]) for c in dhatu]\n",
        "        dhatu_encoded = dhatu_encoded + [self.char_to_idx[\"<PAD>\"]] * (self.max_len - len(dhatu_encoded))\n",
        "        dhatu_tensor = torch.tensor(dhatu_encoded, dtype=torch.long)\n",
        "\n",
        "        # Encode grammatical features\n",
        "        gana = torch.tensor(self.gana_to_idx[item[\"gana\"]], dtype=torch.long)\n",
        "        pada = torch.tensor(self.pada_to_idx[item[\"pada\"]], dtype=torch.long)\n",
        "        lakara = torch.tensor(self.lakara_to_idx[item[\"lakara\"]], dtype=torch.long)\n",
        "        purusha = torch.tensor(self.purusha_to_idx[item[\"purusha\"]], dtype=torch.long)\n",
        "        vacana = torch.tensor(self.vacana_to_idx[item[\"vacana\"]], dtype=torch.long)\n",
        "\n",
        "        # Encode surface form (target)\n",
        "        surface = item[\"surface_form\"]\n",
        "        surface_encoded = [self.char_to_idx.get(c, self.char_to_idx[\"<UNK>\"]) for c in surface]\n",
        "        surface_encoded = [self.char_to_idx[\"<SOS>\"]] + surface_encoded + [self.char_to_idx[\"<EOS>\"]]\n",
        "        surface_encoded = surface_encoded + [self.char_to_idx[\"<PAD>\"]] * (self.max_len + 2 - len(surface_encoded))\n",
        "        surface_tensor = torch.tensor(surface_encoded, dtype=torch.long)\n",
        "\n",
        "        return {\n",
        "            \"dhatu\": dhatu_tensor,\n",
        "            \"gana\": gana,\n",
        "            \"pada\": pada,\n",
        "            \"lakara\": lakara,\n",
        "            \"purusha\": purusha,\n",
        "            \"vacana\": vacana,\n",
        "            \"target\": surface_tensor\n",
        "        }\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, embedding_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        _, hidden = self.gru(embedded)\n",
        "        return hidden\n",
        "\n",
        "class GrammarEncoder(nn.Module):\n",
        "    def __init__(self, num_ganas, num_padas, num_lakaras, num_purushas, num_vacanas, hidden_size):\n",
        "        super(GrammarEncoder, self).__init__()\n",
        "\n",
        "        # Embeddings for each grammatical category\n",
        "        self.gana_embedding = nn.Embedding(num_ganas, hidden_size)\n",
        "        self.pada_embedding = nn.Embedding(num_padas, hidden_size)\n",
        "        self.lakara_embedding = nn.Embedding(num_lakaras, hidden_size)\n",
        "        self.purusha_embedding = nn.Embedding(num_purushas, hidden_size)\n",
        "        self.vacana_embedding = nn.Embedding(num_vacanas, hidden_size)\n",
        "\n",
        "        # Linear layer to combine embeddings\n",
        "        self.combine = nn.Linear(hidden_size * 5, hidden_size)\n",
        "\n",
        "    def forward(self, gana, pada, lakara, purusha, vacana):\n",
        "        gana_emb = self.gana_embedding(gana)\n",
        "        pada_emb = self.pada_embedding(pada)\n",
        "        lakara_emb = self.lakara_embedding(lakara)\n",
        "        purusha_emb = self.purusha_embedding(purusha)\n",
        "        vacana_emb = self.vacana_embedding(vacana)\n",
        "\n",
        "        # Combine all embeddings\n",
        "        combined = torch.cat((gana_emb, pada_emb, lakara_emb, purusha_emb, vacana_emb), dim=1)\n",
        "        output = self.combine(combined)\n",
        "\n",
        "        return output\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, hidden_size, embedding_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size + hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, grammar_embedding):\n",
        "        # Expand grammar embedding to match the sequence length\n",
        "        batch_size = x.size(0)\n",
        "        seq_len = x.size(1)\n",
        "        grammar_expanded = grammar_embedding.unsqueeze(1).expand(batch_size, seq_len, self.hidden_size)\n",
        "\n",
        "        embedded = self.embedding(x)\n",
        "\n",
        "        # Concatenate embedded input and grammar embedding\n",
        "        rnn_input = torch.cat((embedded, grammar_expanded), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(rnn_input, hidden)\n",
        "        prediction = self.out(output)\n",
        "\n",
        "        return prediction, hidden\n",
        "\n",
        "class SanskritMorphologyModel(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_size, embedding_size,\n",
        "                 num_ganas, num_padas, num_lakaras, num_purushas, num_vacanas):\n",
        "        super(SanskritMorphologyModel, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(input_size, hidden_size, embedding_size)\n",
        "        self.grammar_encoder = GrammarEncoder(num_ganas, num_padas, num_lakaras,\n",
        "                                             num_purushas, num_vacanas, hidden_size)\n",
        "        self.decoder = Decoder(output_size, hidden_size, embedding_size)\n",
        "\n",
        "    def forward(self, dhatu, gana, pada, lakara, purusha, vacana, target, teacher_forcing_ratio=0.5):\n",
        "        batch_size = dhatu.size(0)\n",
        "        target_length = target.size(1)\n",
        "        target_vocab_size = self.decoder.out.out_features\n",
        "\n",
        "        # Initialize outputs tensor\n",
        "        outputs = torch.zeros(batch_size, target_length, target_vocab_size).to(dhatu.device)\n",
        "\n",
        "        # Get encoder outputs\n",
        "        encoder_hidden = self.encoder(dhatu)\n",
        "\n",
        "        # Get grammar embedding\n",
        "        grammar_embedding = self.grammar_encoder(gana, pada, lakara, purusha, vacana)\n",
        "\n",
        "        # Initialize decoder input (start with <SOS> token)\n",
        "        decoder_input = target[:, 0].unsqueeze(1)  # Using the first token (<SOS>)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        # Teacher forcing: use real target outputs as each next input\n",
        "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "        for t in range(1, target_length):\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, grammar_embedding)\n",
        "            outputs[:, t, :] = decoder_output.squeeze(1)\n",
        "\n",
        "            # Decide whether to use teacher forcing or not\n",
        "            if use_teacher_forcing:\n",
        "                decoder_input = target[:, t].unsqueeze(1)  # Teacher forcing\n",
        "            else:\n",
        "                # Use our own predictions\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "QMWtAMt_4rgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gs0Yu0-S4rio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, criterion, device, epochs=10):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            # Move data to device\n",
        "            dhatu = batch[\"dhatu\"].to(device)\n",
        "            gana = batch[\"gana\"].to(device)\n",
        "            pada = batch[\"pada\"].to(device)\n",
        "            lakara = batch[\"lakara\"].to(device)\n",
        "            purusha = batch[\"purusha\"].to(device)\n",
        "            vacana = batch[\"vacana\"].to(device)\n",
        "            target = batch[\"target\"].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(dhatu, gana, pada, lakara, purusha, vacana, target)\n",
        "\n",
        "            # Calculate loss (ignoring padding tokens)\n",
        "            loss = criterion(\n",
        "                outputs.view(-1, outputs.size(-1)),\n",
        "                target.view(-1)\n",
        "            )\n",
        "\n",
        "            # Backward pass and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "VE-_WqPH4rk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n0zqsPEj4xmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_surface_form(model, dhatu, gana, pada, lakara, purusha, vacana,\n",
        "                         char_to_idx, idx_to_char, dataset, device, max_length=50):\n",
        "    model.eval()\n",
        "\n",
        "    # Encode dhatu\n",
        "    dhatu_encoded = [char_to_idx.get(c, char_to_idx[\"<UNK>\"]) for c in dhatu]\n",
        "    dhatu_encoded = dhatu_encoded + [char_to_idx[\"<PAD>\"]] * (max_length - len(dhatu_encoded))\n",
        "    dhatu_tensor = torch.tensor([dhatu_encoded], dtype=torch.long).to(device)\n",
        "\n",
        "    # Encode grammatical features\n",
        "    gana_idx = dataset.gana_to_idx[gana]\n",
        "    pada_idx = dataset.pada_to_idx[pada]\n",
        "    lakara_idx = dataset.lakara_to_idx[lakara]\n",
        "    purusha_idx = dataset.purusha_to_idx[purusha]\n",
        "    vacana_idx = dataset.vacana_to_idx[vacana]\n",
        "\n",
        "    gana_tensor = torch.tensor([gana_idx], dtype=torch.long).to(device)\n",
        "    pada_tensor = torch.tensor([pada_idx], dtype=torch.long).to(device)\n",
        "    lakara_tensor = torch.tensor([lakara_idx], dtype=torch.long).to(device)\n",
        "    purusha_tensor = torch.tensor([purusha_idx], dtype=torch.long).to(device)\n",
        "    vacana_tensor = torch.tensor([vacana_idx], dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get encoder outputs\n",
        "        encoder_hidden = model.encoder(dhatu_tensor)\n",
        "\n",
        "        # Get grammar embedding\n",
        "        grammar_embedding = model.grammar_encoder(gana_tensor, pada_tensor,\n",
        "                                                 lakara_tensor, purusha_tensor, vacana_tensor)\n",
        "\n",
        "        # Initialize decoder input with <SOS> token\n",
        "        decoder_input = torch.tensor([[char_to_idx[\"<SOS>\"]]], dtype=torch.long).to(device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        result = []\n",
        "\n",
        "        # Generate characters until <EOS> or max_length\n",
        "        for _ in range(max_length):\n",
        "            decoder_output, decoder_hidden = model.decoder(\n",
        "                decoder_input, decoder_hidden, grammar_embedding)\n",
        "\n",
        "            # Get the most likely next character\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            char_idx = topi.item()\n",
        "\n",
        "            # If <EOS>, stop generation\n",
        "            if char_idx == char_to_idx[\"<EOS>\"]:\n",
        "                break\n",
        "\n",
        "            # If not padding token, add to result\n",
        "            if char_idx != char_to_idx[\"<PAD>\"]:\n",
        "                result.append(idx_to_char[char_idx])\n",
        "\n",
        "            # Update decoder input\n",
        "            decoder_input = topi.detach()\n",
        "\n",
        "        return ''.join(result)"
      ],
      "metadata": {
        "id": "4ja0Gqbo4xow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HipPBh-I4xrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # 1. Generate dataset with dhatu parameters and surface forms\n",
        "    rule_engine = SimplePaniniRules()\n",
        "    dataset_with_surface = create_dataset_with_surface_forms(rule_engine)\n",
        "\n",
        "    # 2. Create character mappings\n",
        "    char_to_idx, idx_to_char = create_char_mappings(dataset_with_surface)\n",
        "\n",
        "    # 3. Create dataset and dataloader\n",
        "    morphology_dataset = SanskritMorphologyDataset(dataset_with_surface, char_to_idx)\n",
        "\n",
        "    # Split into train and test sets\n",
        "    train_size = int(0.8 * len(morphology_dataset))\n",
        "    test_size = len(morphology_dataset) - train_size\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        morphology_dataset, [train_size, test_size])\n",
        "\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "    # 4. Initialize model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SanskritMorphologyModel(\n",
        "        input_size=len(char_to_idx),\n",
        "        output_size=len(char_to_idx),\n",
        "        hidden_size=128,\n",
        "        embedding_size=64,\n",
        "        num_ganas=len(morphology_dataset.ganas),\n",
        "        num_padas=len(morphology_dataset.padas),\n",
        "        num_lakaras=len(morphology_dataset.lakaras),\n",
        "        num_purushas=len(morphology_dataset.purushas),\n",
        "        num_vacanas=len(morphology_dataset.vacanas)\n",
        "    ).to(device)\n",
        "\n",
        "    # 5. Train model\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=char_to_idx[\"<PAD>\"])\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    model = train(model, train_dataloader, optimizer, criterion, device, epochs=10)\n",
        "\n",
        "    # 6. Save model\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'char_to_idx': char_to_idx,\n",
        "        'idx_to_char': idx_to_char\n",
        "    }, 'sanskrit_morphology_model.pth')\n",
        "\n",
        "    # 7. Test model on some examples\n",
        "    print(\"\\nTesting model on examples:\")\n",
        "    test_examples = [\n",
        "        {\"dhatu\": \"भू\", \"gana\": \"भ्वादि\", \"pada\": \"परस्मैपद\", \"lakara\": \"लट्\", \"purusha\": \"प्रथम\", \"vacana\": \"एकवचन\"},\n",
        "        {\"dhatu\": \"कृ\", \"gana\": \"तनादि\", \"pada\": \"परस्मैपद\", \"lakara\": \"लट्\", \"purusha\": \"उत्तम\", \"vacana\": \"बहुवचन\"},\n",
        "        {\"dhatu\": \"गम्\", \"gana\": \"भ्वादि\", \"pada\": \"परस्मैपद\", \"lakara\": \"लृट्\", \"purusha\": \"मध्यम\", \"vacana\": \"एकवचन\"}\n",
        "    ]\n",
        "\n",
        "    for example in test_examples:\n",
        "        # Get the rule-based (expected) form\n",
        "        expected = rule_engine.get_surface_form(example)\n",
        "\n",
        "        # Get the model's prediction\n",
        "        predicted = generate_surface_form(\n",
        "            model, example[\"dhatu\"], example[\"gana\"], example[\"pada\"],\n",
        "            example[\"lakara\"], example[\"purusha\"], example[\"vacana\"],\n",
        "            char_to_idx, idx_to_char, morphology_dataset, device\n",
        "        )\n",
        "\n",
        "        # Print comparison\n",
        "        print(f\"\\nDhatu: {example['dhatu']}, Parameters: {example['lakara']} {example['purusha']} {example['vacana']}\")\n",
        "        print(f\"Expected: {expected}\")\n",
        "        print(f\"Predicted: {predicted}\")\n",
        "\n",
        "        # Calculate accuracy\n",
        "        correct = sum(1 for p, e in zip(predicted, expected) if p == e)\n",
        "        accuracy = correct / max(len(predicted), len(expected))\n",
        "        print(f\"Character accuracy: {accuracy:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "adyi0CIo5HYg",
        "outputId": "bff6a93c-6716-468e-81ee-c7379d40d393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset with 1000 items with surface forms\n",
            "Starting training...\n",
            "Epoch 1/10, Loss: 3.1057\n",
            "Epoch 2/10, Loss: 2.5480\n",
            "Epoch 3/10, Loss: 2.1280\n",
            "Epoch 4/10, Loss: 1.8389\n",
            "Epoch 5/10, Loss: 1.5120\n",
            "Epoch 6/10, Loss: 1.2466\n",
            "Epoch 7/10, Loss: 1.0849\n",
            "Epoch 8/10, Loss: 1.0014\n",
            "Epoch 9/10, Loss: 0.7184\n",
            "Epoch 10/10, Loss: 0.6193\n",
            "\n",
            "Testing model on examples:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Tensors must have same number of dimensions: got 4 and 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-266ef5cca5bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-266ef5cca5bb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# Get the model's prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         predicted = generate_surface_form(\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dhatu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"gana\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pada\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lakara\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"purusha\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"vacana\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-cd117bef81c1>\u001b[0m in \u001b[0;36mgenerate_surface_form\u001b[0;34m(model, dhatu, gana, pada, lakara, purusha, vacana, char_to_idx, idx_to_char, dataset, device, max_length)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Generate characters until <EOS> or max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             decoder_output, decoder_hidden = model.decoder(\n\u001b[0m\u001b[1;32m     40\u001b[0m                 decoder_input, decoder_hidden, grammar_embedding)\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-0d04052cf6c1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hidden, grammar_embedding)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Concatenate embedded input and grammar embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mrnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar_expanded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 4 and 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xlVrYyrk6tZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLKsAZkU6tcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vdTJhk8Y6teN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RL based solutions**"
      ],
      "metadata": {
        "id": "mg_oF_686uUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    \"\"\"Simplified policy network for character generation.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.softmax(x, dim=-1)\n",
        "\n",
        "class ReinforceAgent:\n",
        "    \"\"\"Simplified REINFORCE agent for Sanskrit morphology learning.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=128, lr=0.001, gamma=0.99):\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # Policy network\n",
        "        self.policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim)\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "\n",
        "        # Memory for storing experiences\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.log_probs = []\n",
        "        self.dones = []\n",
        "\n",
        "    def select_action(self, state):\n",
        "        \"\"\"Select an action based on the current policy.\"\"\"\n",
        "        state = torch.FloatTensor(state)\n",
        "        action_probs = self.policy_net(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        action = dist.sample()\n",
        "        log_prob = dist.log_prob(action)\n",
        "\n",
        "        # Store in memory\n",
        "        self.states.append(state)\n",
        "        self.actions.append(action)\n",
        "        self.log_probs.append(log_prob)\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def store_outcome(self, reward, done):\n",
        "        \"\"\"Store reward and done flag from the environment.\"\"\"\n",
        "        self.rewards.append(reward)\n",
        "        self.dones.append(done)\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"Update policy using REINFORCE.\"\"\"\n",
        "        if len(self.states) == 0:\n",
        "            return\n",
        "\n",
        "        # Calculate discounted rewards\n",
        "        discounted_rewards = []\n",
        "        R = 0\n",
        "        for reward, done in zip(reversed(self.rewards), reversed(self.dones)):\n",
        "            if done:\n",
        "                R = 0\n",
        "            R = reward + self.gamma * R\n",
        "            discounted_rewards.insert(0, R)\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        states = torch.stack(self.states)\n",
        "        log_probs = torch.stack(self.log_probs)\n",
        "        rewards = torch.FloatTensor(discounted_rewards)\n",
        "\n",
        "        # Normalize rewards\n",
        "        if len(rewards) > 1:\n",
        "            rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n",
        "\n",
        "        # Calculate loss\n",
        "        policy_loss = -(log_probs * rewards).sum()\n",
        "\n",
        "        # Update network\n",
        "        self.optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Clear memory\n",
        "        self.clear_memory()\n",
        "\n",
        "    def clear_memory(self):\n",
        "        \"\"\"Clear agent's memory after update.\"\"\"\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.log_probs = []\n",
        "        self.dones = []\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"Save model weights.\"\"\"\n",
        "        torch.save(self.policy_net.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        \"\"\"Load model weights.\"\"\"\n",
        "        self.policy_net.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "bK-oFr7H6tgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zUR_8vlO61SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G8ZNGNhj61UT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Generation: Dhatus and Morphological Parameters"
      ],
      "metadata": {
        "id": "Cm000eSL65pM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SanskritDataGenerator:\n",
        "    \"\"\"Generate random dhatus with morphological parameters.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Core Sanskrit verbal roots (dhatus)\n",
        "        self.DHATUS = [\"भू\", \"कृ\", \"गम्\", \"पठ्\", \"वद्\", \"अस्\", \"दृश्\", \"ज्ञा\", \"स्था\", \"पा\",\n",
        "                      \"नी\", \"हृ\", \"दा\", \"दृ\", \"श्रु\", \"त्यज्\", \"जीव्\", \"हन्\", \"खाद्\", \"क्रीड्\"]\n",
        "\n",
        "        # Grammatical categories\n",
        "        self.GANAS = [\"भ्वादि\", \"अदादि\", \"जुहोत्यादि\", \"दिवादि\", \"स्वादि\", \"तुदादि\", \"रुधादि\", \"तनादि\", \"क्र्यादि\", \"चुरादि\"]\n",
        "        self.PADAS = [\"परस्मैपद\", \"आत्मनेपद\", \"उभयपद\"]\n",
        "        self.LAKARAS = [\"लट्\", \"लिट्\", \"लुट्\", \"लृट्\", \"लोट्\", \"लङ्\", \"विधिलिङ्\", \"आशीर्लिङ्\", \"लुङ्\", \"लृङ्\"]\n",
        "        self.PURUSHAS = [\"प्रथम\", \"मध्यम\", \"उत्तम\"]\n",
        "        self.VACANAS = [\"एकवचन\", \"द्विवचन\", \"बहुवचन\"]\n",
        "\n",
        "        # Simplified rule-based implementation of Paninian transformations\n",
        "        self.stem_rules = {\n",
        "            \"भू\": {\"भ्वादि\": \"भव\"},\n",
        "            \"कृ\": {\"तनादि\": \"कर\", \"क्र्यादि\": \"कुरु\"},\n",
        "            \"गम्\": {\"भ्वादि\": \"गच्छ\"},\n",
        "            \"पठ्\": {\"भ्वादि\": \"पठ\"},\n",
        "            \"वद्\": {\"भ्वादि\": \"वद\"},\n",
        "            # Add more mappings as needed\n",
        "        }\n",
        "\n",
        "        # Present tense terminations\n",
        "        self.lat_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ति\", \"द्विवचन\": \"तः\", \"बहुवचन\": \"अन्ति\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"सि\", \"द्विवचन\": \"थः\", \"बहुवचन\": \"थ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"मि\", \"द्विवचन\": \"वः\", \"बहुवचन\": \"मः\"}\n",
        "            },\n",
        "            \"आत्मनेपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ते\", \"द्विवचन\": \"आते\", \"बहुवचन\": \"अन्ते\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"से\", \"द्विवचन\": \"एथे\", \"बहुवचन\": \"ध्वे\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"ए\", \"द्विवचन\": \"वहे\", \"बहुवचन\": \"महे\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_dataset(self, n_samples=1000):\n",
        "        \"\"\"Generate random dhatu parameters dataset.\"\"\"\n",
        "        samples = []\n",
        "        for _ in range(n_samples):\n",
        "            dhatu = random.choice(self.DHATUS)\n",
        "            params = {\n",
        "                \"dhatu\": dhatu,\n",
        "                \"gana\": random.choice(self.GANAS),\n",
        "                \"pada\": random.choice(self.PADAS),\n",
        "                \"lakara\": random.choice(self.LAKARAS),\n",
        "                \"purusha\": random.choice(self.PURUSHAS),\n",
        "                \"vacana\": random.choice(self.VACANAS)\n",
        "            }\n",
        "\n",
        "            # Add the expected surface form using our rule-based system\n",
        "            params[\"surface_form\"] = self.get_surface_form(params)\n",
        "\n",
        "            # Add English meaning/gloss for translation evaluation\n",
        "            params[\"english\"] = self.get_english_gloss(params)\n",
        "\n",
        "            samples.append(params)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def get_surface_form(self, params):\n",
        "        \"\"\"Generate surface form using simplified Paninian rules.\"\"\"\n",
        "        dhatu = params[\"dhatu\"]\n",
        "        gana = params[\"gana\"]\n",
        "        pada = params[\"pada\"]\n",
        "        lakara = params[\"lakara\"]\n",
        "        purusha = params[\"purusha\"]\n",
        "        vacana = params[\"vacana\"]\n",
        "\n",
        "        # This is a simplified version - in a full implementation,\n",
        "        # you would implement complete Paninian rules or use Vidyut-Prakriya\n",
        "\n",
        "        # Get the appropriate verb stem\n",
        "        if dhatu in self.stem_rules and gana in self.stem_rules[dhatu]:\n",
        "            stem = self.stem_rules[dhatu][gana]\n",
        "        else:\n",
        "            # Default stem formation for demonstration\n",
        "            stem = dhatu[:-1] if dhatu.endswith('्') else dhatu\n",
        "\n",
        "        # Apply terminations (only handling लट् present tense properly)\n",
        "        if lakara == \"लट्\" and pada in self.lat_terminations:\n",
        "            if purusha in self.lat_terminations[pada]:\n",
        "                if vacana in self.lat_terminations[pada][purusha]:\n",
        "                    termination = self.lat_terminations[pada][purusha][vacana]\n",
        "                    return stem + termination\n",
        "\n",
        "        # For other combinations, just return a placeholder\n",
        "        return f\"{stem}_{lakara}_{purusha}_{vacana}\"\n",
        "\n",
        "    def get_english_gloss(self, params):\n",
        "        \"\"\"Generate simple English gloss for the Sanskrit form.\"\"\"\n",
        "        dhatu = params[\"dhatu\"]\n",
        "        lakara = params[\"lakara\"]\n",
        "        purusha = params[\"purusha\"]\n",
        "        vacana = params[\"vacana\"]\n",
        "\n",
        "        # Map dhatus to English meanings\n",
        "        dhatu_meanings = {\n",
        "            \"भू\": \"be\", \"कृ\": \"do\", \"गम्\": \"go\", \"पठ्\": \"read\", \"वद्\": \"speak\",\n",
        "            \"अस्\": \"exist\", \"दृश्\": \"see\", \"ज्ञा\": \"know\", \"स्था\": \"stand\", \"पा\": \"drink\",\n",
        "            \"नी\": \"lead\", \"हृ\": \"take\", \"दा\": \"give\", \"दृ\": \"respect\", \"श्रु\": \"hear\",\n",
        "            \"त्यज्\": \"abandon\", \"जीव्\": \"live\", \"हन्\": \"kill\", \"खाद्\": \"eat\", \"क्रीड्\": \"play\"\n",
        "        }\n",
        "\n",
        "        # Map tenses\n",
        "        tense_map = {\n",
        "            \"लट्\": \"present\", \"लिट्\": \"perfect\", \"लुट्\": \"periphrastic future\",\n",
        "            \"लृट्\": \"simple future\", \"लोट्\": \"imperative\", \"लङ्\": \"imperfect\",\n",
        "            \"विधिलिङ्\": \"potential\", \"आशीर्लिङ्\": \"benedictive\", \"लुङ्\": \"aorist\", \"लृङ्\": \"conditional\"\n",
        "        }\n",
        "\n",
        "        # Map persons\n",
        "        person_map = {\n",
        "            \"प्रथम\": \"he/she/it\" if vacana == \"एकवचन\" else \"they\",\n",
        "            \"मध्यम\": \"you\",\n",
        "            \"उत्तम\": \"I\" if vacana == \"एकवचन\" else \"we\"\n",
        "        }\n",
        "\n",
        "        # Map number\n",
        "        number_map = {\n",
        "            \"एकवचन\": \"\",\n",
        "            \"द्विवचन\": \"(dual)\",\n",
        "            \"बहुवचन\": \"(plural)\" if purusha != \"प्रथम\" else \"\"\n",
        "        }\n",
        "\n",
        "        # Get verb meaning\n",
        "        verb = dhatu_meanings.get(dhatu, \"act\")\n",
        "\n",
        "        # Construct English gloss\n",
        "        gloss = f\"{person_map[purusha]} {number_map[vacana]} {verb}s\"\n",
        "\n",
        "        # Adjust for tense\n",
        "        if lakara in tense_map:\n",
        "            if tense_map[lakara] != \"present\":\n",
        "                gloss = f\"{person_map[purusha]} {number_map[vacana]} will {verb}\" if \"future\" in tense_map[lakara] else f\"{person_map[purusha]} {number_map[vacana]} {tense_map[lakara]} {verb}\"\n",
        "\n",
        "        return gloss.strip()"
      ],
      "metadata": {
        "id": "s-OL8jeN61XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Gfy90QH6_i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Vidyut-Prakriya Alternative for Verification"
      ],
      "metadata": {
        "id": "NW_F78Qi7Aez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SanskritVerifier:\n",
        "    \"\"\"Verifies Sanskrit forms against Paninian rules.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data_generator = SanskritDataGenerator()\n",
        "\n",
        "    def verify_form(self, predicted_form, params):\n",
        "        \"\"\"Check if predicted form matches the expected form.\"\"\"\n",
        "        expected_form = self.data_generator.get_surface_form(params)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        correct_chars = sum(1 for p, e in zip(predicted_form, expected_form) if p == e)\n",
        "        total_chars = max(len(predicted_form), len(expected_form))\n",
        "        accuracy = correct_chars / total_chars if total_chars > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"is_correct\": predicted_form == expected_form,\n",
        "            \"accuracy\": accuracy,\n",
        "            \"expected\": expected_form,\n",
        "            \"predicted\": predicted_form\n",
        "        }\n",
        "\n"
      ],
      "metadata": {
        "id": "vwuRsQH86_lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45AZyv8L6_oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Reinforcement Learning Environment"
      ],
      "metadata": {
        "id": "NgcmSCqV7Grm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SanskritMorphologyEnv:\n",
        "    \"\"\"RL environment for Sanskrit morphological transformations.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.verifier = SanskritVerifier()\n",
        "\n",
        "        # Define action and state spaces\n",
        "        self.char_to_idx, self.idx_to_char = self._create_char_mappings()\n",
        "        self.action_space = len(self.char_to_idx) + 1  # All possible chars + EOS\n",
        "\n",
        "        # Features for state representation\n",
        "        self.ganas = sorted(set(item[\"gana\"] for item in dataset))\n",
        "        self.padas = sorted(set(item[\"pada\"] for item in dataset))\n",
        "        self.lakaras = sorted(set(item[\"lakara\"] for item in dataset))\n",
        "        self.purushas = sorted(set(item[\"purusha\"] for item in dataset))\n",
        "        self.vacanas = sorted(set(item[\"vacana\"] for item in dataset))\n",
        "\n",
        "        self.gana_to_idx = {g: i for i, g in enumerate(self.ganas)}\n",
        "        self.pada_to_idx = {p: i for i, p in enumerate(self.padas)}\n",
        "        self.lakara_to_idx = {l: i for i, l in enumerate(self.lakaras)}\n",
        "        self.purusha_to_idx = {p: i for i, p in enumerate(self.purushas)}\n",
        "        self.vacana_to_idx = {v: i for i, v in enumerate(self.vacanas)}\n",
        "\n",
        "        # Maximum sequence length\n",
        "        self.max_len = 30\n",
        "        self.reset()\n",
        "\n",
        "    def _create_char_mappings(self):\n",
        "        \"\"\"Create character to index mappings from the dataset.\"\"\"\n",
        "        chars = self.get_all_chars()\n",
        "        char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "        idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "        # Add EOS token\n",
        "        idx_to_char[len(char_to_idx)] = \"<EOS>\"\n",
        "        return char_to_idx, idx_to_char\n",
        "\n",
        "    def get_all_chars(self):\n",
        "        \"\"\"Get all unique characters in the dataset.\"\"\"\n",
        "        chars = set()\n",
        "        for item in self.dataset:\n",
        "            chars.update(item[\"dhatu\"])\n",
        "            chars.update(item[\"surface_form\"])\n",
        "        return sorted(chars)\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the environment with a random sample.\"\"\"\n",
        "        self.current_step = 0\n",
        "        self.current_sample = random.choice(self.dataset)\n",
        "        self.current_output = \"\"\n",
        "        self.done = False\n",
        "        return self._get_state(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Take an action (generate a character) and return next state, reward, etc.\"\"\"\n",
        "        # Convert action index to character\n",
        "        if action < len(self.char_to_idx):\n",
        "            char = self.idx_to_char[action]\n",
        "            self.current_output += char\n",
        "        else:\n",
        "            # End of sequence action\n",
        "            self.done = True\n",
        "\n",
        "        self.current_step += 1\n",
        "\n",
        "        # Check if max length reached\n",
        "        if self.current_step >= self.max_len:\n",
        "            self.done = True\n",
        "\n",
        "        # Calculate reward\n",
        "        reward = self._calculate_reward()\n",
        "\n",
        "        # Get next state\n",
        "        next_state = self._get_state()\n",
        "\n",
        "        return next_state, reward, self.done, False, {}\n",
        "\n",
        "    def _get_state(self):\n",
        "        \"\"\"Get enhanced state representation.\"\"\"\n",
        "        # Encode dhatu with one-hot encoding\n",
        "        dhatu = self.current_sample[\"dhatu\"]\n",
        "        dhatu_encoded = [0] * 128  # Unicode range for Devanagari\n",
        "        for c in dhatu:\n",
        "            if ord(c) < 128:\n",
        "                dhatu_encoded[ord(c)] = 1\n",
        "\n",
        "        # One-hot encode grammatical features\n",
        "        gana_vec = [0] * len(self.ganas)\n",
        "        gana_vec[self.gana_to_idx[self.current_sample[\"gana\"]]] = 1\n",
        "\n",
        "        pada_vec = [0] * len(self.padas)\n",
        "        pada_vec[self.pada_to_idx[self.current_sample[\"pada\"]]] = 1\n",
        "\n",
        "        lakara_vec = [0] * len(self.lakaras)\n",
        "        lakara_vec[self.lakara_to_idx[self.current_sample[\"lakara\"]]] = 1\n",
        "\n",
        "        purusha_vec = [0] * len(self.purushas)\n",
        "        purusha_vec[self.purusha_to_idx[self.current_sample[\"purusha\"]]] = 1\n",
        "\n",
        "        vacana_vec = [0] * len(self.vacanas)\n",
        "        vacana_vec[self.vacana_to_idx[self.current_sample[\"vacana\"]]] = 1\n",
        "\n",
        "        # Encode current output with positional awareness\n",
        "        output_encoded = []\n",
        "        for i, c in enumerate(self.current_output):\n",
        "            if c in self.char_to_idx:\n",
        "                # Add position information\n",
        "                pos_encoded = [0] * len(self.char_to_idx)\n",
        "                pos_encoded[self.char_to_idx[c]] = 1\n",
        "                output_encoded.extend(pos_encoded)\n",
        "            if i >= 5:  # Limit to first 5 characters to keep state size reasonable\n",
        "                break\n",
        "\n",
        "        # Pad if needed\n",
        "        output_encoded = output_encoded + [0] * (5 * len(self.char_to_idx) - len(output_encoded))\n",
        "\n",
        "        # Combine all features\n",
        "        state = dhatu_encoded + gana_vec + pada_vec + lakara_vec + purusha_vec + vacana_vec + output_encoded\n",
        "        return state\n",
        "\n",
        "    def _calculate_reward(self):\n",
        "      \"\"\"Calculate a more informative reward based on character-level matching.\"\"\"\n",
        "      if not self.done:\n",
        "          return 0  # No intermediate rewards\n",
        "\n",
        "      # Get expected form\n",
        "      expected = self.current_sample[\"surface_form\"]\n",
        "      predicted = self.current_output\n",
        "\n",
        "      # Perfect match gets highest reward\n",
        "      if predicted == expected:\n",
        "          return 10.0\n",
        "\n",
        "      # Character-level matching with position awareness\n",
        "      match_score = 0\n",
        "      for i, (p, e) in enumerate(zip(predicted, expected)):\n",
        "          if p == e:\n",
        "              # Reward early correct matches more highly\n",
        "              position_weight = 1.0 - (i / len(expected) * 0.5) if len(expected) > 0 else 0\n",
        "              match_score += position_weight\n",
        "\n",
        "      # Penalize length differences\n",
        "      length_penalty = abs(len(predicted) - len(expected)) * 0.2\n",
        "\n",
        "      # Reward for stem correctness (first part of the word)\n",
        "      stem_length = min(3, len(expected)//2)\n",
        "      if predicted[:stem_length] == expected[:stem_length]:\n",
        "          match_score += 2.0\n",
        "\n",
        "      # Calculate final reward\n",
        "      reward = match_score - length_penalty\n",
        "\n",
        "      # Scale between -1 and 10\n",
        "      return max(-1.0, min(10.0, reward))"
      ],
      "metadata": {
        "id": "V3Jj7LYm7IHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L3rk7lXE7ISU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKibV1Sx7IU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. RL Agent: Policy Gradient Implementation"
      ],
      "metadata": {
        "id": "Zlqq4k0K7Q4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "    \"\"\"Policy network for character generation.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
        "\n",
        "        # Fix the LSTM input dimension issue\n",
        "        # LSTM expects (batch_size, seq_len, input_features)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=hidden_dim,  # This must match the output dimension from fc1\n",
        "            hidden_size=hidden_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.fc2 = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First linear layer\n",
        "        x = F.relu(self.fc1(x))  # Shape: [batch_size, hidden_dim]\n",
        "\n",
        "        # Reshape for LSTM\n",
        "        batch_size = x.size(0) if x.dim() > 1 else 1\n",
        "        if x.dim() == 1:  # Handle single sample case\n",
        "            x = x.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "        x = x.view(batch_size, 1, self.hidden_dim)  # Ensure correct shape for LSTM\n",
        "\n",
        "        # LSTM layer\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "\n",
        "        # Extract output and pass through final layer\n",
        "        x = lstm_out[:, -1, :]  # Take the last timestep output\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.softmax(x, dim=-1)\n",
        "\n",
        "class ValueNetwork(nn.Module):\n",
        "    \"\"\"Value network for PPO.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, hidden_dim=128):\n",
        "        super(ValueNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "class PPOAgent:\n",
        "    \"\"\"PPO agent for Sanskrit morphology learning.\"\"\"\n",
        "\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=128, lr=0.001, gamma=0.99,\n",
        "                 clip_ratio=0.2, target_kl=0.01, vf_coef=0.5):\n",
        "        self.gamma = gamma\n",
        "        self.clip_ratio = clip_ratio\n",
        "        self.target_kl = target_kl\n",
        "        self.vf_coef = vf_coef\n",
        "\n",
        "        # Policy and value networks\n",
        "        self.policy_net = PolicyNetwork(state_dim, action_dim, hidden_dim)\n",
        "        self.value_net = ValueNetwork(state_dim, hidden_dim)\n",
        "\n",
        "        # Optimizers\n",
        "        self.policy_optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "        self.value_optimizer = torch.optim.Adam(self.value_net.parameters(), lr=lr)\n",
        "\n",
        "        # Memory for storing experiences\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.log_probs = []\n",
        "        self.values = []\n",
        "        self.dones = []\n",
        "\n",
        "    def select_action(self, state):\n",
        "        \"\"\"Select an action based on the current policy.\"\"\"\n",
        "        state = torch.FloatTensor(state)\n",
        "        action_probs = self.policy_net(state)\n",
        "        dist = Categorical(action_probs)\n",
        "        action = dist.sample()\n",
        "        log_prob = dist.log_prob(action)\n",
        "        value = self.value_net(state)\n",
        "\n",
        "        # Store in memory\n",
        "        self.states.append(state)\n",
        "        self.actions.append(action)\n",
        "        self.log_probs.append(log_prob)\n",
        "        self.values.append(value)\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def store_outcome(self, reward, done):\n",
        "        \"\"\"Store reward and done flag from the environment.\"\"\"\n",
        "        self.rewards.append(reward)\n",
        "        self.dones.append(done)\n",
        "\n",
        "    def compute_returns(self):\n",
        "        \"\"\"Compute returns for each time step.\"\"\"\n",
        "        returns = []\n",
        "        R = 0\n",
        "\n",
        "        for reward, done in zip(reversed(self.rewards), reversed(self.dones)):\n",
        "            if done:\n",
        "                R = 0\n",
        "            R = reward + self.gamma * R\n",
        "            returns.insert(0, R)\n",
        "\n",
        "        returns = torch.tensor(returns)\n",
        "\n",
        "        # Normalize returns\n",
        "        if len(returns) > 1:\n",
        "            returns = (returns - returns.mean()) / (returns.std() + 1e-8)\n",
        "\n",
        "        return returns\n",
        "\n",
        "    def update(self, num_epochs=10, batch_size=64):\n",
        "        \"\"\"Update policy and value networks using collected experiences.\"\"\"\n",
        "        if len(self.states) == 0:\n",
        "            return\n",
        "\n",
        "        # Convert to tensors\n",
        "        states = torch.stack(self.states)\n",
        "        actions = torch.stack(self.actions)\n",
        "        old_log_probs = torch.stack(self.log_probs)\n",
        "        values = torch.cat(self.values)\n",
        "\n",
        "        # Compute returns and advantages\n",
        "        returns = self.compute_returns()\n",
        "        advantages = returns - values.detach()\n",
        "\n",
        "        # PPO update loop\n",
        "        for _ in range(num_epochs):\n",
        "            # Create minibatches\n",
        "            indices = torch.randperm(len(states))\n",
        "            for start_idx in range(0, len(states), batch_size):\n",
        "                end_idx = min(start_idx + batch_size, len(states))\n",
        "                batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "                # Get batch data\n",
        "                batch_states = states[batch_indices]\n",
        "                batch_actions = actions[batch_indices]\n",
        "                batch_old_log_probs = old_log_probs[batch_indices]\n",
        "                batch_returns = returns[batch_indices]\n",
        "                batch_advantages = advantages[batch_indices]\n",
        "\n",
        "                # Update policy network\n",
        "                self.policy_optimizer.zero_grad()\n",
        "                policy_output = self.policy_net(batch_states)\n",
        "                dist = Categorical(policy_output)\n",
        "                batch_new_log_probs = dist.log_prob(batch_actions)\n",
        "\n",
        "                # Compute policy loss with clipping\n",
        "                ratio = torch.exp(batch_new_log_probs - batch_old_log_probs)\n",
        "                surr1 = ratio * batch_advantages\n",
        "                surr2 = torch.clamp(ratio, 1 - self.clip_ratio, 1 + self.clip_ratio) * batch_advantages\n",
        "                policy_loss = -torch.min(surr1, surr2).mean()\n",
        "\n",
        "                # Update policy network\n",
        "                policy_loss.backward()\n",
        "                self.policy_optimizer.step()\n",
        "\n",
        "                # Update value network separately\n",
        "                self.value_optimizer.zero_grad()\n",
        "                value_pred = self.value_net(batch_states).squeeze(-1)\n",
        "                value_loss = F.mse_loss(value_pred, batch_returns)\n",
        "                value_loss.backward()\n",
        "                self.value_optimizer.step()\n",
        "\n",
        "        # Clear memory\n",
        "        self.clear_memory()\n",
        "\n",
        "    def clear_memory(self):\n",
        "        \"\"\"Clear agent's memory after update.\"\"\"\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.log_probs = []\n",
        "        self.values = []\n",
        "        self.dones = []\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"Save model weights.\"\"\"\n",
        "        torch.save({\n",
        "            'policy_state_dict': self.policy_net.state_dict(),\n",
        "            'value_state_dict': self.value_net.state_dict(),\n",
        "        }, path)\n",
        "\n",
        "    def load(self, path):\n",
        "        \"\"\"Load model weights.\"\"\"\n",
        "        checkpoint = torch.load(path)\n",
        "        self.policy_net.load_state_dict(checkpoint['policy_state_dict'])\n",
        "        self.value_net.load_state_dict(checkpoint['value_state_dict'])"
      ],
      "metadata": {
        "id": "WX9yohBz7IXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R-WfHbUk76XT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTrUoSVn76Zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Training Loop"
      ],
      "metadata": {
        "id": "zATZ7Rwc79Sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_agent(env, agent, num_episodes=500, max_steps=30, update_freq=20):\n",
        "    \"\"\"Train the agent.\"\"\"\n",
        "    episode_rewards = []\n",
        "    accuracy_history = []\n",
        "\n",
        "    progress_bar = tqdm(range(num_episodes), desc=\"Training\")\n",
        "\n",
        "    for episode in progress_bar:\n",
        "        state, _ = env.reset()\n",
        "        episode_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            action = agent.select_action(state)\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "            agent.store_outcome(reward, done)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        # Update agent\n",
        "        if (episode + 1) % update_freq == 0:\n",
        "            agent.update()\n",
        "\n",
        "        episode_rewards.append(episode_reward)\n",
        "\n",
        "        # Calculate and track accuracy periodically\n",
        "        if (episode + 1) % 50 == 0:\n",
        "            # Evaluate on a small subset\n",
        "            eval_accuracy = evaluate_accuracy(env, agent, num_samples=20)\n",
        "            accuracy_history.append(eval_accuracy)\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'reward': f'{episode_reward:.2f}',\n",
        "                'accuracy': f'{eval_accuracy:.2f}'\n",
        "            })\n",
        "\n",
        "    return episode_rewards, accuracy_history\n",
        "\n",
        "def evaluate_accuracy(env, agent, num_samples=20):\n",
        "    \"\"\"Evaluate model accuracy on a subset of examples.\"\"\"\n",
        "    correct = 0\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        state, _ = env.reset()\n",
        "        env.done = False\n",
        "\n",
        "        while not env.done:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state)\n",
        "                action_probs = agent.policy_net(state_tensor)\n",
        "                action = torch.argmax(action_probs).item()\n",
        "\n",
        "            state, _, done, _, _ = env.step(action)\n",
        "            if env.current_step >= env.max_len:\n",
        "                break\n",
        "\n",
        "        verification = env.verifier.verify_form(env.current_output, env.current_sample)\n",
        "        if verification[\"is_correct\"]:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / num_samples"
      ],
      "metadata": {
        "id": "qRqqDtoi76cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jb_FyMXW8ArQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "class QwenSanskritEnhancer:\n",
        "    \"\"\"Uses Qwen model to enhance Sanskrit processing capabilities.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"Qwen/Qwen1.5-0.5B\"):\n",
        "        print(f\"Loading Qwen model: {model_name}\")\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "            self.model_loaded = True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Qwen model: {e}\")\n",
        "            print(\"Continuing without Qwen model.\")\n",
        "            self.model_loaded = False\n",
        "\n",
        "    def explain_panini_rule(self, dhatu, morphological_params):\n",
        "        \"\"\"Explain the Paninian grammar rule being applied.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return \"Qwen model not available for explanation.\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Explain the Paninian grammar rule that transforms the Sanskrit root (dhatu) \"{dhatu}\"\n",
        "        with the following morphological parameters:\n",
        "        - Gana (verb class): {morphological_params['gana']}\n",
        "        - Pada (voice): {morphological_params['pada']}\n",
        "        - Lakara (tense/mood): {morphological_params['lakara']}\n",
        "        - Purusha (person): {morphological_params['purusha']}\n",
        "        - Vacana (number): {morphological_params['vacana']}\n",
        "\n",
        "        Explain step by step how these parameters affect the final surface form according to Panini's Ashtadhyayi.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=250,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            explanation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the generated part (removing the prompt)\n",
        "            explanation = explanation[len(prompt):]\n",
        "\n",
        "            return explanation.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error generating explanation: {e}\"\n",
        "\n",
        "    def verify_form_with_reasoning(self, predicted, expected, params):\n",
        "        \"\"\"Verify the form with LLM-based reasoning about correctness.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return None\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        In Sanskrit morphology, the verbal root (dhatu) \"{params['dhatu']}\" with parameters:\n",
        "        - Gana: {params['gana']}\n",
        "        - Pada: {params['pada']}\n",
        "        - Lakara: {params['lakara']}\n",
        "        - Purusha: {params['purusha']}\n",
        "        - Vacana: {params['vacana']}\n",
        "\n",
        "        should transform to: {expected}\n",
        "\n",
        "        The model generated: {predicted}\n",
        "\n",
        "        Analyze if the generated form is correct. If not, explain what specific Paninian rule was violated\n",
        "        and how the transformation should have proceeded.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=300,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            analysis = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the generated part\n",
        "            analysis = analysis[len(prompt):]\n",
        "\n",
        "            return analysis.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error generating analysis: {e}\"\n",
        "\n",
        "    def translate_english_to_sanskrit(self, english_text, morphological_context=None):\n",
        "        \"\"\"Translate English to Sanskrit with morphological awareness.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return \"Qwen model not available for translation.\"\n",
        "\n",
        "        if morphological_context:\n",
        "            context = f\"\"\"\n",
        "            - Grammatical context: {morphological_context['gana']} verb class,\n",
        "            {morphological_context['pada']} voice, {morphological_context['lakara']} tense,\n",
        "            {morphological_context['purusha']} person, {morphological_context['vacana']} number\n",
        "            \"\"\"\n",
        "        else:\n",
        "            context = \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Translate the following English text to Sanskrit using Devanagari script.\n",
        "        {context}\n",
        "\n",
        "        English: {english_text}\n",
        "        Sanskrit:\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=100,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the translation\n",
        "            if \"Sanskrit:\" in translation:\n",
        "                translation = translation.split(\"Sanskrit:\")[1].strip()\n",
        "\n",
        "            return translation\n",
        "        except Exception as e:\n",
        "            return f\"Error generating translation: {e}\""
      ],
      "metadata": {
        "id": "zEuZ4nbyCm_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VitDUDZyCnBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qlBEu38SG8LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-D_YgAyG_0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# . Add Supervised Pre-training"
      ],
      "metadata": {
        "id": "URWm-vbEHANw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_pretraining(model, dataset, char_to_idx, idx_to_char, epochs=50, batch_size=32):\n",
        "    \"\"\"Pre-train the policy network using supervised learning.\"\"\"\n",
        "    print(\"Starting supervised pre-training...\")\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Create environment to use its encoding functions\n",
        "    env = SanskritMorphologyEnv(dataset)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Shuffle data each epoch\n",
        "        indices = torch.randperm(len(dataset))\n",
        "\n",
        "        for start_idx in range(0, len(dataset), batch_size):\n",
        "            end_idx = min(start_idx + batch_size, len(dataset))\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            batch_states = []\n",
        "            batch_targets = []\n",
        "\n",
        "            # Prepare batch data\n",
        "            for idx in batch_indices:\n",
        "                item = dataset[idx]\n",
        "\n",
        "                # Set current sample in environment\n",
        "                env.current_sample = item\n",
        "                env.current_output = \"\"\n",
        "\n",
        "                # Get initial state\n",
        "                state = env._get_state()\n",
        "                batch_states.append(state)\n",
        "\n",
        "                # Get target (expected surface form)\n",
        "                expected = item[\"surface_form\"]\n",
        "                target_chars = [char_to_idx.get(c, 0) for c in expected] + [len(char_to_idx)]  # Add EOS token\n",
        "                batch_targets.append(target_chars)\n",
        "\n",
        "            # Convert to tensors\n",
        "            batch_states = torch.FloatTensor(batch_states)\n",
        "\n",
        "            # Calculate loss for each character position\n",
        "            optimizer.zero_grad()\n",
        "            total_batch_loss = 0\n",
        "\n",
        "            # For simplicity, use cross-entropy loss on first character only\n",
        "            outputs = model(batch_states)\n",
        "\n",
        "            # Create target tensor with first characters\n",
        "            targets = torch.tensor([t[0] if t else 0 for t in batch_targets], dtype=torch.long)\n",
        "\n",
        "            # Calculate loss\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/num_batches:.4f}\")\n",
        "\n",
        "    print(\"Supervised pre-training completed!\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "XqJ4A5IbG8Rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dQNEDrF9G8U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# .Main function"
      ],
      "metadata": {
        "id": "IS-6pyzfI9vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # 1. Generate dataset\n",
        "    print(\"Generating Sanskrit dataset...\")\n",
        "    generator = SanskritDataGenerator()\n",
        "    full_dataset = generator.generate_dataset(1000)  # Generate a larger initial dataset\n",
        "\n",
        "    # Simplify the dataset to focus on present tense and active voice for initial learning\n",
        "    print(\"Simplifying dataset for easier learning...\")\n",
        "    simplified_dataset = [item for item in full_dataset if item[\"lakara\"] == \"लट्\" and item[\"pada\"] == \"परस्मैपद\"]\n",
        "    if len(simplified_dataset) < 100:  # Ensure we have enough examples\n",
        "        print(\"Not enough examples with the simplified criteria, generating more...\")\n",
        "        while len(simplified_dataset) < 100:\n",
        "            more_items = generator.generate_dataset(100)\n",
        "            simplified_items = [item for item in more_items if item[\"lakara\"] == \"लट्\" and item[\"pada\"] == \"परस्मैपद\"]\n",
        "            simplified_dataset.extend(simplified_items)\n",
        "\n",
        "    # Use the simplified dataset for initial training\n",
        "    dataset = simplified_dataset[:500]  # Limit to 500 examples\n",
        "    print(f\"Using simplified dataset with {len(dataset)} examples\")\n",
        "\n",
        "    # Split into train, validation, test\n",
        "    random.shuffle(dataset)\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    train_data = dataset[:train_size]\n",
        "    val_data = dataset[train_size:train_size+val_size]\n",
        "    test_data = dataset[train_size+val_size:]\n",
        "\n",
        "    # 2. Create RL environment\n",
        "    print(\"Setting up RL environment...\")\n",
        "    env = SanskritMorphologyEnv(train_data)\n",
        "\n",
        "    # Calculate state and action dimensions based on enhanced state representation\n",
        "    dhatu_dim = 128  # Unicode range\n",
        "    grammar_dim = len(env.ganas) + len(env.padas) + len(env.lakaras) + len(env.purushas) + len(env.vacanas)\n",
        "    output_dim = 5 * len(env.char_to_idx)  # 5 characters with one-hot encoding\n",
        "    state_dim = dhatu_dim + grammar_dim + output_dim\n",
        "    action_dim = env.action_space\n",
        "\n",
        "    # 3. Initialize Qwen enhancer\n",
        "    print(\"Initializing Qwen model for enhanced capabilities...\")\n",
        "    qwen_enhancer = QwenSanskritEnhancer()\n",
        "\n",
        "    # 4. Create RL agent\n",
        "    print(\"Creating RL agent for Sanskrit morphology...\")\n",
        "    agent = ReinforceAgent(state_dim, action_dim)\n",
        "\n",
        "    # 5. Pre-train the agent's policy network with supervised learning\n",
        "    print(\"Starting supervised pre-training...\")\n",
        "    agent.policy_net = supervised_pretraining(\n",
        "        agent.policy_net,\n",
        "        train_data,\n",
        "        env.char_to_idx,\n",
        "        env.idx_to_char,\n",
        "        epochs=30\n",
        "    )\n",
        "\n",
        "    # 6. Train with curriculum learning\n",
        "    print(\"Training RL agent with curriculum learning...\")\n",
        "    rewards, accuracies, env = curriculum_training(\n",
        "        env,\n",
        "        agent,\n",
        "        full_dataset,  # Full dataset for later curriculum stages\n",
        "        generator,\n",
        "        episodes_per_level=100\n",
        "    )\n",
        "\n",
        "    # Save the trained model\n",
        "    agent.save(\"sanskrit_morphology_model.pt\")\n",
        "\n",
        "    # 7. Evaluate on test data\n",
        "    print(\"Evaluating on test data...\")\n",
        "    test_accuracy = evaluate_accuracy(env, agent, num_samples=50)\n",
        "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # 8. Generate examples with LLM explanations\n",
        "    print(\"\\nGenerating examples with explanations:\")\n",
        "    samples = random.sample(test_data, 5)\n",
        "\n",
        "    results = []\n",
        "    for sample in samples:\n",
        "        # Generate form using trained policy\n",
        "        env.current_sample = sample\n",
        "        env.current_output = \"\"\n",
        "        env.current_step = 0\n",
        "        env.done = False\n",
        "        state = env._get_state()\n",
        "\n",
        "        while not env.done:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state)\n",
        "                action_probs = agent.policy_net(state_tensor)\n",
        "                action = torch.argmax(action_probs).item()\n",
        "\n",
        "            state, _, done, _, _ = env.step(action)\n",
        "            if env.current_step >= env.max_len:\n",
        "                break\n",
        "\n",
        "        # Get verification\n",
        "        verification = env.verifier.verify_form(env.current_output, sample)\n",
        "\n",
        "        # Get Qwen explanation if available\n",
        "        panini_explanation = qwen_enhancer.explain_panini_rule(sample[\"dhatu\"], sample)\n",
        "        verification_reasoning = qwen_enhancer.verify_form_with_reasoning(\n",
        "            env.current_output, verification[\"expected\"], sample)\n",
        "\n",
        "        # Store results\n",
        "        result = {\n",
        "            \"dhatu\": sample[\"dhatu\"],\n",
        "            \"parameters\": {\n",
        "                \"gana\": sample[\"gana\"],\n",
        "                \"pada\": sample[\"pada\"],\n",
        "                \"lakara\": sample[\"lakara\"],\n",
        "                \"purusha\": sample[\"purusha\"],\n",
        "                \"vacana\": sample[\"vacana\"]\n",
        "            },\n",
        "            \"english\": sample[\"english\"],\n",
        "            \"expected\": verification[\"expected\"],\n",
        "            \"generated\": env.current_output,\n",
        "            \"is_correct\": verification[\"is_correct\"],\n",
        "            \"accuracy\": verification[\"accuracy\"],\n",
        "            \"panini_explanation\": panini_explanation,\n",
        "            \"verification_reasoning\": verification_reasoning\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Print example\n",
        "        print(f\"\\nDhatu: {sample['dhatu']}\")\n",
        "        print(f\"Parameters: {sample['gana']}, {sample['pada']}, {sample['lakara']}, \"\n",
        "              f\"{sample['purusha']}, {sample['vacana']}\")\n",
        "        print(f\"English meaning: {sample['english']}\")\n",
        "        print(f\"Expected form: {verification['expected']}\")\n",
        "        print(f\"Generated form: {env.current_output}\")\n",
        "        print(f\"Correct: {'Yes' if verification['is_correct'] else 'No'}\")\n",
        "\n",
        "        if verification_reasoning:\n",
        "            print(\"\\nVerification reasoning:\")\n",
        "            print(verification_reasoning[:200] + \"...\" if len(verification_reasoning) > 200 else verification_reasoning)\n",
        "\n",
        "        print(\"--------------------\")\n",
        "\n",
        "    # 9. English to Sanskrit translation with morphological awareness\n",
        "    print(\"\\nDemonstrating English to Sanskrit translation with morphological awareness:\")\n",
        "    for sample in samples[:3]:\n",
        "        english_text = sample[\"english\"]\n",
        "        morphological_context = {\n",
        "            \"gana\": sample[\"gana\"],\n",
        "            \"pada\": sample[\"pada\"],\n",
        "            \"lakara\": sample[\"lakara\"],\n",
        "            \"purusha\": sample[\"purusha\"],\n",
        "            \"vacana\": sample[\"vacana\"]\n",
        "        }\n",
        "\n",
        "        # Translate with morphological context\n",
        "        translation = qwen_enhancer.translate_english_to_sanskrit(english_text, morphological_context)\n",
        "\n",
        "        print(f\"\\nEnglish: {english_text}\")\n",
        "        print(f\"Context: {sample['gana']} verb, {sample['lakara']} tense, {sample['purusha']} person\")\n",
        "        print(f\"Translation: {translation}\")\n",
        "        print(f\"Expected verb form: {sample['surface_form']}\")\n",
        "        print(\"--------------------\")\n",
        "\n",
        "    # 10. Plot results\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(rewards)\n",
        "    plt.title('RL Training Rewards')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(0, len(accuracies)*50, 50), accuracies)\n",
        "    plt.title('Morphology Accuracy')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sanskrit_morphology_results.png')\n",
        "    plt.show()\n",
        "\n",
        "    # 11. Save results\n",
        "    output = {\n",
        "        \"test_accuracy\": test_accuracy,\n",
        "        \"examples\": results,\n",
        "        \"training\": {\n",
        "            \"rewards\": rewards,\n",
        "            \"accuracies\": accuracies\n",
        "        }\n",
        "    }\n",
        "\n",
        "    with open(\"sanskrit_results.json\", \"w\") as f:\n",
        "        json.dump(output, f, indent=2)\n",
        "\n",
        "    print(\"\\nResearch Question: Will learning Paninian grammar rules improve English→Sanskrit translation?\")\n",
        "    print(f\"\\nBased on our model achieving {test_accuracy:.2%} accuracy in generating correct Sanskrit forms,\")\n",
        "    print(\"we can conclude that a computational approach to Paninian grammar is feasible.\")\n",
        "    print(\"The integration of the Qwen model provides enhanced capabilities for:\")\n",
        "    print(\"1. Explaining the Paninian rules being applied\")\n",
        "    print(\"2. Verifying and reasoning about morphological transformations\")\n",
        "    print(\"3. Improving English→Sanskrit translation with morphological awareness\")\n",
        "\n",
        "    print(\"\\nThese results suggest that incorporating Paninian grammar knowledge into\")\n",
        "    print(\"translation systems would improve English→Sanskrit translation quality,\")\n",
        "    print(\"especially for grammatical correctness and morphological accuracy.\")"
      ],
      "metadata": {
        "id": "q9U6xpv2CnDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. English-to-Sanskrit Translation Model"
      ],
      "metadata": {
        "id": "HyMJ6AAQ8DRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class EnglishToSanskritTranslator(nn.Module):\n",
        "#     \"\"\"Seq2Seq model for English to Sanskrit translation.\"\"\"\n",
        "\n",
        "#     def __init__(self, eng_vocab_size, sans_vocab_size, embedding_dim=128, hidden_dim=256,\n",
        "#                  morph_features_dim=50, use_morphology=True):\n",
        "#         super(EnglishToSanskritTranslator, self).__init__()\n",
        "\n",
        "#         self.embedding_dim = embedding_dim\n",
        "#         self.hidden_dim = hidden_dim\n",
        "#         self.use_morphology = use_morphology\n",
        "\n",
        "#         # Embeddings\n",
        "#         self.eng_embedding = nn.Embedding(eng_vocab_size, embedding_dim)\n",
        "#         self.sans_embedding = nn.Embedding(sans_vocab_size, embedding_dim)\n",
        "\n",
        "#         # Encoder\n",
        "#         self.encoder = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "\n",
        "#         # Morphological feature integration (optional)\n",
        "#         if use_morphology:\n",
        "#             self.morph_projection = nn.Linear(morph_features_dim, hidden_dim)\n",
        "#             decoder_input_dim = embedding_dim + hidden_dim * 2  # Embed + context + morph\n",
        "#         else:\n",
        "#             decoder_input_dim = embedding_dim + hidden_dim * 2  # Embed + context\n",
        "\n",
        "#         # Decoder\n",
        "#         self.decoder = nn.LSTM(decoder_input_dim, hidden_dim, batch_first=True)\n",
        "#         self.out = nn.Linear(hidden_dim, sans_vocab_size)\n",
        "\n",
        "#     def forward(self, eng_seq, sans_seq=None, morph_features=None, teacher_forcing_ratio=0.5):\n",
        "#         batch_size = eng_seq.size(0)\n",
        "\n",
        "#         # Encoder\n",
        "#         eng_embedded = self.eng_embedding(eng_seq)\n",
        "#         encoder_outputs, (hidden, cell) = self.encoder(eng_embedded)\n",
        "\n",
        "#         # Process bidirectional hidden state\n",
        "#         hidden = hidden.view(2, 2, batch_size, -1)[-1]  # Take last layer's states\n",
        "#         hidden = hidden.transpose(0, 1).contiguous().view(1, batch_size, -1)\n",
        "\n",
        "#         cell = cell.view(2, 2, batch_size, -1)[-1]\n",
        "#         cell = cell.transpose(0, 1).contiguous().view(1, batch_size, -1)\n",
        "\n",
        "#         # Integrate morphological features if available\n",
        "#         if self.use_morphology and morph_features is not None:\n",
        "#             morph_projected = self.morph_projection(morph_features).unsqueeze(1)\n",
        "\n",
        "#             # Update hidden state with morphological information\n",
        "#             hidden = hidden + morph_projected.transpose(0, 1)\n",
        "\n",
        "#         # Prepare for decoding\n",
        "#         max_len = sans_seq.size(1) if sans_seq is not None else 50\n",
        "#         decoder_input = torch.zeros(batch_size, 1, dtype=torch.long).fill_(1)  # <SOS> token\n",
        "\n",
        "#         outputs = torch.zeros(batch_size, max_len, self.out.out_features)\n",
        "\n",
        "#         for t in range(max_len):\n",
        "#             # Decoder step\n",
        "#             sans_embedded = self.sans_embedding(decoder_input)\n",
        "\n",
        "#             # Attention mechanism (simplified)\n",
        "#             attn_weights = torch.bmm(sans_embedded, encoder_outputs.transpose(1, 2))\n",
        "#             attn_weights = F.softmax(attn_weights, dim=2)\n",
        "#             context = torch.bmm(attn_weights, encoder_outputs)\n",
        "\n",
        "#             # Concatenate embedding and context\n",
        "#             decoder_input_combined = torch.cat((sans_embedded, context), dim=2)\n",
        "\n",
        "#             # Pass through decoder\n",
        "#             decoder_output, (hidden, cell) = self.decoder(decoder_input_combined, (hidden, cell))\n",
        "#             prediction = self.out(decoder_output)\n",
        "\n",
        "#             outputs[:, t:t+1] = prediction\n",
        "\n",
        "#             # Teacher forcing\n",
        "#             use_teacher_forcing = random.random() < teacher_forcing_ratio and sans_seq is not None\n",
        "\n",
        "#             if use_teacher_forcing and t < max_len - 1:\n",
        "#                 decoder_input = sans_seq[:, t+1:t+2]\n",
        "#             else:\n",
        "#                 # Use model's own prediction\n",
        "#                 _, topi = prediction.topk(1)\n",
        "#                 decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "#         return outputs"
      ],
      "metadata": {
        "id": "UZya8Bye8Atx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Aq5Qrx88IAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NR1j0omS8IDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Morphology-Enhanced Translation Training"
      ],
      "metadata": {
        "id": "L9SByqDS8KVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_translation_data(dataset, english_tokenizer, sanskrit_tokenizer):\n",
        "    \"\"\"Prepare translation data with morphological features.\"\"\"\n",
        "    eng_texts = [item[\"english\"] for item in dataset]\n",
        "    sans_texts = [item[\"surface_form\"] for item in dataset]\n",
        "\n",
        "    # Tokenize text\n",
        "    eng_tokens = english_tokenizer(eng_texts, padding=True, return_tensors=\"pt\")\n",
        "    sans_tokens = sanskrit_tokenizer(sans_texts, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "    # Extract morphological features\n",
        "    morph_features = []\n",
        "    for item in dataset:\n",
        "        # One-hot encode each morphological feature\n",
        "        features = []\n",
        "        # Add features for gana, pada, lakara, purusha, vacana\n",
        "        # (Implementation details omitted for brevity)\n",
        "        morph_features.append(features)\n",
        "\n",
        "    morph_features = torch.tensor(morph_features, dtype=torch.float)\n",
        "\n",
        "    return eng_tokens.input_ids, sans_tokens.input_ids, morph_features\n",
        "\n",
        "def train_translator(translator, train_data, valid_data, optimizer, criterion, num_epochs=10,\n",
        "                     use_morphology=True, morph_ablation=False):\n",
        "    \"\"\"Train the translator with or without morphological features.\"\"\"\n",
        "    train_eng, train_sans, train_morph = train_data\n",
        "    valid_eng, valid_sans, valid_morph = valid_data\n",
        "\n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    valid_bleu_scores = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        translator.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for i in range(0, len(train_eng), 32):  # Batch size 32\n",
        "            batch_eng = train_eng[i:i+32]\n",
        "            batch_sans = train_sans[i:i+32]\n",
        "            batch_morph = train_morph[i:i+32] if use_morphology and not morph_ablation else None\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = translator(batch_eng, batch_sans, batch_morph)\n",
        "            output_flat = output.view(-1, output.size(-1))\n",
        "            target_flat = batch_sans.view(-1)\n",
        "\n",
        "            loss = criterion(output_flat, target_flat)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        train_losses.append(epoch_loss / (len(train_eng) // 32))\n",
        "\n",
        "        # Validation\n",
        "        translator.eval()\n",
        "        valid_loss = 0\n",
        "        all_bleu = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(valid_eng), 32):\n",
        "                batch_eng = valid_eng[i:i+32]\n",
        "                batch_sans = valid_sans[i:i+32]\n",
        "                batch_morph = valid_morph[i:i+32] if use_morphology and not morph_ablation else None\n",
        "\n",
        "                output = translator(batch_eng, batch_sans, batch_morph, teacher_forcing_ratio=0)\n",
        "                output_flat = output.view(-1, output.size(-1))\n",
        "                target_flat = batch_sans.view(-1)\n",
        "\n",
        "                loss = criterion(output_flat, target_flat)\n",
        "                valid_loss += loss.item()\n",
        "\n",
        "                # Calculate BLEU scores\n",
        "                _, predicted = output.max(dim=2)\n",
        "                for j in range(len(batch_eng)):\n",
        "                    pred_tokens = predicted[j].tolist()\n",
        "                    true_tokens = batch_sans[j].tolist()\n",
        "\n",
        "                    # Remove padding and special tokens\n",
        "                    pred_tokens = [t for t in pred_tokens if t > 2]\n",
        "                    true_tokens = [t for t in true_tokens if t > 2]\n",
        "\n",
        "                    bleu = sentence_bleu([true_tokens], pred_tokens,\n",
        "                                         smoothing_function=SmoothingFunction().method1)\n",
        "                    all_bleu.append(bleu)\n",
        "\n",
        "        valid_losses.append(valid_loss / (len(valid_eng) // 32))\n",
        "        valid_bleu_scores.append(sum(all_bleu) / len(all_bleu) if all_bleu else 0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]:.4f}, \"\n",
        "              f\"Valid Loss: {valid_losses[-1]:.4f}, BLEU: {valid_bleu_scores[-1]:.4f}\")\n",
        "\n",
        "    return train_losses, valid_losses, valid_bleu_scores"
      ],
      "metadata": {
        "id": "7nDf4jua8IFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zG7HjiIY8IIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Main Execution Script"
      ],
      "metadata": {
        "id": "S-1AkQo38P3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # 1. Generate dataset\n",
        "    print(\"Generating Sanskrit dataset...\")\n",
        "    generator = SanskritDataGenerator()\n",
        "    dataset = generator.generate_dataset(5000)\n",
        "\n",
        "    # Split into train, validation, test\n",
        "    random.shuffle(dataset)\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    train_data = dataset[:train_size]\n",
        "    val_data = dataset[train_size:train_size+val_size]\n",
        "    test_data = dataset[train_size+val_size:]\n",
        "\n",
        "    # 2. Create RL environment\n",
        "    print(\"Setting up RL environment...\")\n",
        "    env = SanskritMorphologyEnv(train_data)\n",
        "\n",
        "    # Calculate state and action dimensions\n",
        "    state_dim = 10 + 5 + env.max_len  # dhatu + grammar features + output so far\n",
        "    action_dim = env.action_space\n",
        "\n",
        "    # 3. Create and train RL agent\n",
        "    print(\"Training RL agent for Sanskrit morphology...\")\n",
        "    agent = PPOAgent(state_dim, action_dim)\n",
        "    rewards, accuracies = train_agent(env, agent, num_episodes=2000)\n",
        "\n",
        "    # Save model\n",
        "    agent.save(\"sanskrit_morphology_model.pt\")\n",
        "\n",
        "    # 4. Evaluate morphology model\n",
        "    print(\"Evaluating morphology model...\")\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    results = []\n",
        "\n",
        "    for item in test_data:\n",
        "        # Reset environment with this test example\n",
        "        env.current_sample = item\n",
        "        env.current_output = \"\"\n",
        "        env.current_step = 0\n",
        "        env.done = False\n",
        "        state = env._get_state()\n",
        "\n",
        "        # Generate form using trained policy\n",
        "        while not env.done:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state)\n",
        "                action_probs = agent.policy_net(state_tensor)\n",
        "                action = torch.argmax(action_probs).item()\n",
        "\n",
        "            state, _, done, _, _ = env.step(action)\n",
        "            if env.current_step >= env.max_len:\n",
        "                break\n",
        "\n",
        "        # Verify result\n",
        "        verification = env.verifier.verify_form(env.current_output, item)\n",
        "        results.append({**verification, \"params\": item})\n",
        "\n",
        "        if verification[\"is_correct\"]:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "    morph_accuracy = correct / total\n",
        "    print(f\"Morphology model accuracy: {morph_accuracy:.4f}\")\n",
        "\n",
        "    # Analyze error patterns\n",
        "    error_analysis = env.verifier.analyze_error_patterns(results)\n",
        "    print(\"Error patterns:\", error_analysis[\"error_patterns\"])\n",
        "    print(\"Errors by category:\", error_analysis[\"error_by_category\"])\n",
        "\n",
        "    # 5. Train English->Sanskrit translation models\n",
        "    print(\"Preparing for translation task...\")\n",
        "\n",
        "    # Create simple tokenizers\n",
        "    def create_tokenizer(texts):\n",
        "        vocab = set()\n",
        "        for text in texts:\n",
        "            vocab.update(text)\n",
        "        vocab = sorted(vocab)\n",
        "        token_to_idx = {token: idx+3 for idx, token in enumerate(vocab)}\n",
        "        token_to_idx[\"<PAD>\"] = 0\n",
        "        token_to_idx[\"<SOS>\"] = 1\n",
        "        token_to_idx[\"<EOS>\"] = 2\n",
        "        return token_to_idx\n",
        "\n",
        "    english_texts = [item[\"english\"] for item in dataset]\n",
        "    sanskrit_texts = [item[\"surface_form\"] for item in dataset]\n",
        "\n",
        "    eng_tokenizer = create_tokenizer(english_texts)\n",
        "    sans_tokenizer = create_tokenizer(sanskrit_texts)\n",
        "\n",
        "    def tokenize_text(texts, tokenizer):\n",
        "        result = []\n",
        "        for text in texts:\n",
        "            tokens = [tokenizer.get(c, tokenizer[\"<UNK>\"]) for c in text]\n",
        "            tokens = [tokenizer[\"<SOS>\"]] + tokens + [tokenizer[\"<EOS>\"]]\n",
        "            result.append(tokens)\n",
        "        return result\n",
        "\n",
        "    # Tokenize data\n",
        "    eng_tokens = tokenize_text(english_texts, eng_tokenizer)\n",
        "    sans_tokens = tokenize_text(sanskrit_texts, sans_tokenizer)\n",
        "\n",
        "    # Create morphological feature vectors\n",
        "    def create_morph_features(data_items):\n",
        "        morph_features = []\n",
        "        for item in data_items:\n",
        "            # One-hot encode each morphological feature\n",
        "            gana_vec = [0] * len(generator.GANAS)\n",
        "            gana_idx = generator.GANAS.index(item[\"gana\"])\n",
        "            gana_vec[gana_idx] = 1\n",
        "\n",
        "            pada_vec = [0] * len(generator.PADAS)\n",
        "            pada_idx = generator.PADAS.index(item[\"pada\"])\n",
        "            pada_vec[pada_idx] = 1\n",
        "\n",
        "            lakara_vec = [0] * len(generator.LAKARAS)\n",
        "            lakara_idx = generator.LAKARAS.index(item[\"lakara\"])\n",
        "            lakara_vec[lakara_idx] = 1\n",
        "\n",
        "            purusha_vec = [0] * len(generator.PURUSHAS)\n",
        "            purusha_idx = generator.PURUSHAS.index(item[\"purusha\"])\n",
        "            purusha_vec[purusha_idx] = 1\n",
        "\n",
        "            vacana_vec = [0] * len(generator.VACANAS)\n",
        "            vacana_idx = generator.VACANAS.index(item[\"vacana\"])\n",
        "            vacana_vec[vacana_idx] = 1\n",
        "\n",
        "            features = gana_vec + pada_vec + lakara_vec + purusha_vec + vacana_vec\n",
        "            morph_features.append(features)\n",
        "        return morph_features\n",
        "\n",
        "    morph_features = create_morph_features(dataset)\n",
        "\n",
        "    # Pad sequences\n",
        "    def pad_sequences(sequences, max_len=None):\n",
        "        if max_len is None:\n",
        "            max_len = max(len(seq) for seq in sequences)\n",
        "\n",
        "        padded = []\n",
        "        for seq in sequences:\n",
        "            padded.append(seq + [0] * (max_len - len(seq)))\n",
        "        return torch.tensor(padded)\n",
        "\n",
        "    eng_padded = pad_sequences(eng_tokens)\n",
        "    sans_padded = pad_sequences(sans_tokens)\n",
        "    morph_tensor = torch.tensor(morph_features, dtype=torch.float)\n",
        "\n",
        "    # Split data for translation task\n",
        "    train_eng = eng_padded[:train_size]\n",
        "    train_sans = sans_padded[:train_size]\n",
        "    train_morph = morph_tensor[:train_size]\n",
        "\n",
        "    val_eng = eng_padded[train_size:train_size+val_size]\n",
        "    val_sans = sans_padded[train_size:train_size+val_size]\n",
        "    val_morph = morph_tensor[train_size:train_size+val_size]\n",
        "\n",
        "    test_eng = eng_padded[train_size+val_size:]\n",
        "    test_sans = sans_padded[train_size+val_size:]\n",
        "    test_morph = morph_tensor[train_size+val_size:]\n",
        "\n",
        "    # 6. Train and evaluate translation models\n",
        "    print(\"Training translation models...\")\n",
        "\n",
        "    # Model with morphology\n",
        "    translator_with_morph = EnglishToSanskritTranslator(\n",
        "        eng_vocab_size=len(eng_tokenizer),\n",
        "        sans_vocab_size=len(sans_tokenizer),\n",
        "        morph_features_dim=len(morph_features[0]),\n",
        "        use_morphology=True\n",
        "    )\n",
        "\n",
        "    # Model without morphology (ablation)\n",
        "    translator_without_morph = EnglishToSanskritTranslator(\n",
        "        eng_vocab_size=len(eng_tokenizer),\n",
        "        sans_vocab_size=len(sans_tokenizer),\n",
        "        morph_features_dim=len(morph_features[0]),\n",
        "        use_morphology=False\n",
        "    )\n",
        "\n",
        "    # Train with morphology\n",
        "    print(\"Training translator WITH morphological features...\")\n",
        "    optimizer_with_morph = torch.optim.Adam(translator_with_morph.parameters())\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding\n",
        "\n",
        "    train_data = (train_eng, train_sans, train_morph)\n",
        "    valid_data = (val_eng, val_sans, val_morph)\n",
        "\n",
        "    _, _, bleu_with_morph = train_translator(\n",
        "        translator_with_morph,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        optimizer_with_morph,\n",
        "        criterion,\n",
        "        num_epochs=15,\n",
        "        use_morphology=True\n",
        "    )\n",
        "\n",
        "    # Train without morphology (ablation)\n",
        "    print(\"Training translator WITHOUT morphological features (ablation)...\")\n",
        "    optimizer_without_morph = torch.optim.Adam(translator_without_morph.parameters())\n",
        "\n",
        "    _, _, bleu_without_morph = train_translator(\n",
        "        translator_without_morph,\n",
        "        train_data,\n",
        "        valid_data,\n",
        "        optimizer_without_morph,\n",
        "        criterion,\n",
        "        num_epochs=15,\n",
        "        use_morphology=False\n",
        "    )\n",
        "\n",
        "    # 7. Final evaluation and comparison\n",
        "    print(\"Evaluating translation models on test set...\")\n",
        "\n",
        "    def evaluate_translator(model, test_eng, test_sans, test_morph=None, use_morphology=True):\n",
        "        model.eval()\n",
        "        all_bleu = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(test_eng), 32):\n",
        "                batch_eng = test_eng[i:i+32]\n",
        "                batch_sans = test_sans[i:i+32]\n",
        "                batch_morph = test_morph[i:i+32] if use_morphology else None\n",
        "\n",
        "                output = model(batch_eng, batch_sans, batch_morph, teacher_forcing_ratio=0)\n",
        "                _, predicted = output.max(dim=2)\n",
        "\n",
        "                for j in range(len(batch_eng)):\n",
        "                    pred_tokens = predicted[j].tolist()\n",
        "                    true_tokens = batch_sans[j].tolist()\n",
        "\n",
        "                    # Remove padding and special tokens\n",
        "                    pred_tokens = [t for t in pred_tokens if t > 2]\n",
        "                    true_tokens = [t for t in true_tokens if t > 2]\n",
        "\n",
        "                    bleu = sentence_bleu([true_tokens], pred_tokens,\n",
        "                                         smoothing_function=SmoothingFunction().method1)\n",
        "                    all_bleu.append(bleu)\n",
        "\n",
        "        return sum(all_bleu) / len(all_bleu) if all_bleu else 0\n",
        "\n",
        "    test_bleu_with_morph = evaluate_translator(\n",
        "        translator_with_morph, test_eng, test_sans, test_morph, use_morphology=True)\n",
        "\n",
        "    test_bleu_without_morph = evaluate_translator(\n",
        "        translator_without_morph, test_eng, test_sans, use_morphology=False)\n",
        "\n",
        "    print(f\"Test BLEU WITH morphology: {test_bleu_with_morph:.4f}\")\n",
        "    print(f\"Test BLEU WITHOUT morphology: {test_bleu_without_morph:.4f}\")\n",
        "    print(f\"Improvement: {(test_bleu_with_morph - test_bleu_without_morph) * 100:.2f}%\")\n",
        "\n",
        "    # 8. Plot results\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.plot(rewards)\n",
        "    plt.title('RL Training Rewards')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.plot(accuracies)\n",
        "    plt.title('Morphology Accuracy During Training')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.plot(bleu_with_morph, label='With Morphology')\n",
        "    plt.plot(bleu_without_morph, label='Without Morphology')\n",
        "    plt.title('Translation BLEU Scores During Training')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('BLEU Score')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.bar(['With Morph', 'Without Morph'], [test_bleu_with_morph, test_bleu_without_morph])\n",
        "    plt.title('Final Test BLEU Scores')\n",
        "    plt.ylabel('BLEU Score')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sanskrit_results.png')\n",
        "    plt.show()\n",
        "\n",
        "    # 9. Save results\n",
        "    results = {\n",
        "        'morphology_accuracy': morph_accuracy,\n",
        "        'error_analysis': error_analysis,\n",
        "        'translation_bleu_with_morph': test_bleu_with_morph,\n",
        "        'translation_bleu_without_morph': test_bleu_without_morph,\n",
        "        'improvement_percentage': (test_bleu_with_morph - test_bleu_without_morph) * 100\n",
        "    }\n",
        "\n",
        "    with open('sanskrit_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2)\n",
        "\n",
        "    print(\"Results saved to 'sanskrit_results.json' and 'sanskrit_results.png'\")\n",
        "\n",
        "    # 10. Generate example translations\n",
        "    print(\"\\nExample translations:\")\n",
        "\n",
        "    idx_to_eng_token = {idx: token for token, idx in eng_tokenizer.items()}\n",
        "    idx_to_sans_token = {idx: token for token, idx in sans_tokenizer.items()}\n",
        "\n",
        "    def decode_tokens(tokens, idx_to_token):\n",
        "        return ''.join([idx_to_token.get(t, '') for t in tokens if t > 2])\n",
        "\n",
        "    sample_indices = random.sample(range(len(test_eng)), 5)\n",
        "\n",
        "    for idx in sample_indices:\n",
        "        eng_input = test_eng[idx:idx+1]\n",
        "        morph_input = test_morph[idx:idx+1]\n",
        "        true_sans = test_sans[idx].tolist()\n",
        "\n",
        "        # Generate with morphology\n",
        "        with torch.no_grad():\n",
        "            output_with_morph = translator_with_morph(\n",
        "                eng_input, None, morph_input, teacher_forcing_ratio=0)\n",
        "            _, pred_with_morph = output_with_morph.max(dim=2)\n",
        "            pred_with_morph = pred_with_morph[0].tolist()\n",
        "\n",
        "        # Generate without morphology\n",
        "        with torch.no_grad():\n",
        "            output_without_morph = translator_without_morph(\n",
        "                eng_input, None, None, teacher_forcing_ratio=0)\n",
        "            _, pred_without_morph = output_without_morph.max(dim=2)\n",
        "            pred_without_morph = pred_without_morph[0].tolist()\n",
        "\n",
        "        # Decode\n",
        "        eng_text = decode_tokens(eng_input[0].tolist(), idx_to_eng_token)\n",
        "        true_sans_text = decode_tokens(true_sans, idx_to_sans_token)\n",
        "        pred_with_morph_text = decode_tokens(pred_with_morph, idx_to_sans_token)\n",
        "        pred_without_morph_text = decode_tokens(pred_without_morph, idx_to_sans_token)\n",
        "\n",
        "        print(f\"English: {eng_text}\")\n",
        "        print(f\"True Sanskrit: {true_sans_text}\")\n",
        "        print(f\"Predicted WITH morphology: {pred_with_morph_text}\")\n",
        "        print(f\"Predicted WITHOUT morphology: {pred_without_morph_text}\")\n",
        "        print(\"------------------------\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "CWNXwQYj8SYn",
        "outputId": "92195ad1-8374-4eab-cd0c-998a177e6359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Sanskrit dataset...\n",
            "Setting up RL environment...\n",
            "Training RL agent for Sanskrit morphology...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 9/2000 [00:00<01:52, 17.71it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-75b5dd6e7e48>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-46-75b5dd6e7e48>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training RL agent for Sanskrit morphology...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPOAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Save model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-d98b33c061cc>\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(env, agent, num_episodes, max_steps, update_freq)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Update policy every update_freq episodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepisode\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Track episodic rewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-ac161043bbd2>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;31m# Update policy network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mpolicy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0jTV1gV4K1_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "73vyDI0zK2By"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9Wiaq56K2Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyUtODs6K2HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dYUgUjj8K2KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OAta9c9DK2Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgsK4UcyK2O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8p3-gg0FK2Rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BS_8P-ZkK2Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0j-zua_K2WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "IjQX_W12K2Yy",
        "outputId": "d0123243-7632-4bac-d6ba-5fc60e25a51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-70-32ff6fd5f8b8>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-32ff6fd5f8b8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    A new code\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **A new code**"
      ],
      "metadata": {
        "id": "oVaw7UDTK37k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Working Solution for Sanskrit Morphology Learning\n",
        "\n",
        "import random\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 1. Data Generator\n",
        "class SanskritDataGenerator:\n",
        "    \"\"\"Generate random dhatus with morphological parameters.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Core Sanskrit verbal roots (dhatus)\n",
        "        self.DHATUS = [\"भू\", \"कृ\", \"गम्\", \"पठ्\", \"वद्\", \"अस्\", \"दृश्\", \"ज्ञा\", \"स्था\", \"पा\",\n",
        "                      \"नी\", \"हृ\", \"दा\", \"दृ\", \"श्रु\", \"त्यज्\", \"जीव्\", \"हन्\", \"खाद्\", \"क्रीड्\"]\n",
        "\n",
        "        # Grammatical categories\n",
        "        self.GANAS = [\"भ्वादि\", \"अदादि\", \"जुहोत्यादि\", \"दिवादि\", \"स्वादि\", \"तुदादि\", \"रुधादि\", \"तनादि\", \"क्र्यादि\", \"चुरादि\"]\n",
        "        self.PADAS = [\"परस्मैपद\", \"आत्मनेपद\", \"उभयपद\"]\n",
        "        self.LAKARAS = [\"लट्\", \"लिट्\", \"लुट्\", \"लृट्\", \"लोट्\", \"लङ्\", \"विधिलिङ्\", \"आशीर्लिङ्\", \"लुङ्\", \"लृङ्\"]\n",
        "        self.PURUSHAS = [\"प्रथम\", \"मध्यम\", \"उत्तम\"]\n",
        "        self.VACANAS = [\"एकवचन\", \"द्विवचन\", \"बहुवचन\"]\n",
        "\n",
        "        # Simplified rule-based implementation of Paninian transformations\n",
        "        self.stem_rules = {\n",
        "            \"भू\": {\"भ्वादि\": \"भव\"},\n",
        "            \"कृ\": {\"तनादि\": \"कर\", \"क्र्यादि\": \"कुरु\"},\n",
        "            \"गम्\": {\"भ्वादि\": \"गच्छ\"},\n",
        "            \"पठ्\": {\"भ्वादि\": \"पठ\"},\n",
        "            \"वद्\": {\"भ्वादि\": \"वद\"},\n",
        "            \"अस्\": {\"अदादि\": \"अस्\"},\n",
        "            \"दृश्\": {\"अदादि\": \"पश्य\"},\n",
        "            \"ज्ञा\": {\"क्र्यादि\": \"जान\"},\n",
        "            \"स्था\": {\"भ्वादि\": \"तिष्ठ\"},\n",
        "            \"पा\": {\"अदादि\": \"पिब\"}\n",
        "        }\n",
        "\n",
        "        # Present tense terminations\n",
        "        self.lat_terminations = {\n",
        "            \"परस्मैपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ति\", \"द्विवचन\": \"तः\", \"बहुवचन\": \"अन्ति\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"सि\", \"द्विवचन\": \"थः\", \"बहुवचन\": \"थ\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"मि\", \"द्विवचन\": \"वः\", \"बहुवचन\": \"मः\"}\n",
        "            },\n",
        "            \"आत्मनेपद\": {\n",
        "                \"प्रथम\": {\"एकवचन\": \"ते\", \"द्विवचन\": \"आते\", \"बहुवचन\": \"अन्ते\"},\n",
        "                \"मध्यम\": {\"एकवचन\": \"से\", \"द्विवचन\": \"एथे\", \"बहुवचन\": \"ध्वे\"},\n",
        "                \"उत्तम\": {\"एकवचन\": \"ए\", \"द्विवचन\": \"वहे\", \"बहुवचन\": \"महे\"}\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def generate_dataset(self, n_samples=1000):\n",
        "        \"\"\"Generate random dhatu parameters dataset.\"\"\"\n",
        "        samples = []\n",
        "        for _ in range(n_samples):\n",
        "            dhatu = random.choice(self.DHATUS)\n",
        "            params = {\n",
        "                \"dhatu\": dhatu,\n",
        "                \"gana\": random.choice(self.GANAS),\n",
        "                \"pada\": random.choice(self.PADAS),\n",
        "                \"lakara\": random.choice(self.LAKARAS),\n",
        "                \"purusha\": random.choice(self.PURUSHAS),\n",
        "                \"vacana\": random.choice(self.VACANAS)\n",
        "            }\n",
        "\n",
        "            # Add the expected surface form using our rule-based system\n",
        "            params[\"surface_form\"] = self.get_surface_form(params)\n",
        "\n",
        "            # Add English meaning/gloss for translation\n",
        "            params[\"english\"] = self.get_english_gloss(params)\n",
        "\n",
        "            samples.append(params)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def get_surface_form(self, params):\n",
        "        \"\"\"Generate surface form using simplified Paninian rules.\"\"\"\n",
        "        dhatu = params[\"dhatu\"]\n",
        "        gana = params[\"gana\"]\n",
        "        pada = params[\"pada\"]\n",
        "        lakara = params[\"lakara\"]\n",
        "        purusha = params[\"purusha\"]\n",
        "        vacana = params[\"vacana\"]\n",
        "\n",
        "        # Get the appropriate verb stem\n",
        "        if dhatu in self.stem_rules and gana in self.stem_rules[dhatu]:\n",
        "            stem = self.stem_rules[dhatu][gana]\n",
        "        else:\n",
        "            # Default stem formation for demonstration\n",
        "            stem = dhatu[:-1] if dhatu.endswith('्') else dhatu\n",
        "\n",
        "        # Apply terminations (only handling लट् present tense properly)\n",
        "        if lakara == \"लट्\" and pada in self.lat_terminations:\n",
        "            if purusha in self.lat_terminations[pada]:\n",
        "                if vacana in self.lat_terminations[pada][purusha]:\n",
        "                    termination = self.lat_terminations[pada][purusha][vacana]\n",
        "                    return stem + termination\n",
        "\n",
        "        # For other combinations, just return a placeholder\n",
        "        return f\"{stem}_{lakara}_{purusha}_{vacana}\"\n",
        "\n",
        "    def get_english_gloss(self, params):\n",
        "        \"\"\"Generate simple English gloss for the Sanskrit form.\"\"\"\n",
        "        dhatu = params[\"dhatu\"]\n",
        "        lakara = params[\"lakara\"]\n",
        "        purusha = params[\"purusha\"]\n",
        "        vacana = params[\"vacana\"]\n",
        "\n",
        "        # Map dhatus to English meanings\n",
        "        dhatu_meanings = {\n",
        "            \"भू\": \"be\", \"कृ\": \"do\", \"गम्\": \"go\", \"पठ्\": \"read\", \"वद्\": \"speak\",\n",
        "            \"अस्\": \"exist\", \"दृश्\": \"see\", \"ज्ञा\": \"know\", \"स्था\": \"stand\", \"पा\": \"drink\",\n",
        "            \"नी\": \"lead\", \"हृ\": \"take\", \"दा\": \"give\", \"दृ\": \"respect\", \"श्रु\": \"hear\",\n",
        "            \"त्यज्\": \"abandon\", \"जीव्\": \"live\", \"हन्\": \"kill\", \"खाद्\": \"eat\", \"क्रीड्\": \"play\"\n",
        "        }\n",
        "\n",
        "        # Map tenses\n",
        "        tense_map = {\n",
        "            \"लट्\": \"present\", \"लिट्\": \"perfect\", \"लुट्\": \"periphrastic future\",\n",
        "            \"लृट्\": \"simple future\", \"लोट्\": \"imperative\", \"लङ्\": \"imperfect\"\n",
        "        }\n",
        "\n",
        "        # Map persons\n",
        "        person_map = {\n",
        "            \"प्रथम\": \"he/she/it\" if vacana == \"एकवचन\" else \"they\",\n",
        "            \"मध्यम\": \"you\",\n",
        "            \"उत्तम\": \"I\" if vacana == \"एकवचन\" else \"we\"\n",
        "        }\n",
        "\n",
        "        # Get verb meaning\n",
        "        verb = dhatu_meanings.get(dhatu, \"act\")\n",
        "\n",
        "        # Construct English gloss\n",
        "        gloss = f\"{person_map[purusha]} {verb}s\"\n",
        "\n",
        "        # Adjust for tense\n",
        "        if lakara in tense_map:\n",
        "            if tense_map[lakara] != \"present\":\n",
        "                gloss = f\"{person_map[purusha]} will {verb}\" if \"future\" in tense_map[lakara] else f\"{person_map[purusha]} {tense_map[lakara]} {verb}\"\n",
        "\n",
        "        return gloss.strip()\n",
        "\n",
        "# 2. Verifier\n",
        "class SanskritVerifier:\n",
        "    \"\"\"Verifies Sanskrit forms against Paninian rules.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data_generator = SanskritDataGenerator()\n",
        "\n",
        "    def verify_form(self, predicted_form, params):\n",
        "        \"\"\"Check if predicted form matches the expected form.\"\"\"\n",
        "        expected_form = self.data_generator.get_surface_form(params)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        correct_chars = sum(1 for p, e in zip(predicted_form, expected_form) if p == e)\n",
        "        total_chars = max(len(predicted_form), len(expected_form))\n",
        "        accuracy = correct_chars / total_chars if total_chars > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"is_correct\": predicted_form == expected_form,\n",
        "            \"accuracy\": accuracy,\n",
        "            \"expected\": expected_form,\n",
        "            \"predicted\": predicted_form\n",
        "        }\n",
        "\n",
        "# 3. Environment with Improved State Representation and Reward\n",
        "class SanskritMorphologyEnv:\n",
        "    \"\"\"RL environment for Sanskrit morphological transformations.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "        self.verifier = SanskritVerifier()\n",
        "\n",
        "        # Define action and state spaces\n",
        "        self.char_to_idx, self.idx_to_char = self._create_char_mappings()\n",
        "        self.action_space = len(self.char_to_idx) + 1  # All possible chars + EOS\n",
        "\n",
        "        # Features for state representation\n",
        "        self.ganas = sorted(set(item[\"gana\"] for item in dataset))\n",
        "        self.padas = sorted(set(item[\"pada\"] for item in dataset))\n",
        "        self.lakaras = sorted(set(item[\"lakara\"] for item in dataset))\n",
        "        self.purushas = sorted(set(item[\"purusha\"] for item in dataset))\n",
        "        self.vacanas = sorted(set(item[\"vacana\"] for item in dataset))\n",
        "\n",
        "        self.gana_to_idx = {g: i for i, g in enumerate(self.ganas)}\n",
        "        self.pada_to_idx = {p: i for i, p in enumerate(self.padas)}\n",
        "        self.lakara_to_idx = {l: i for i, l in enumerate(self.lakaras)}\n",
        "        self.purusha_to_idx = {p: i for i, p in enumerate(self.purushas)}\n",
        "        self.vacana_to_idx = {v: i for i, v in enumerate(self.vacanas)}\n",
        "\n",
        "        # Maximum sequence length\n",
        "        self.max_len = 30\n",
        "        self.reset()\n",
        "\n",
        "    def _create_char_mappings(self):\n",
        "        \"\"\"Create character to index mappings from the dataset.\"\"\"\n",
        "        chars = self.get_all_chars()\n",
        "        char_to_idx = {c: i for i, c in enumerate(chars)}\n",
        "        idx_to_char = {i: c for c, i in char_to_idx.items()}\n",
        "        # Add EOS token\n",
        "        idx_to_char[len(char_to_idx)] = \"<EOS>\"\n",
        "        return char_to_idx, idx_to_char\n",
        "\n",
        "    def get_all_chars(self):\n",
        "        \"\"\"Get all unique characters in the dataset.\"\"\"\n",
        "        chars = set()\n",
        "        for item in self.dataset:\n",
        "            chars.update(item[\"dhatu\"])\n",
        "            chars.update(item[\"surface_form\"])\n",
        "        return sorted(chars)\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the environment with a random sample.\"\"\"\n",
        "        self.current_step = 0\n",
        "        self.current_sample = random.choice(self.dataset)\n",
        "        self.current_output = \"\"\n",
        "        self.done = False\n",
        "        return self._get_state(), {}\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Take an action (generate a character) and return next state, reward, etc.\"\"\"\n",
        "        # Convert action index to character\n",
        "        if action < len(self.char_to_idx):\n",
        "            char = self.idx_to_char[action]\n",
        "            self.current_output += char\n",
        "        else:\n",
        "            # End of sequence action\n",
        "            self.done = True\n",
        "\n",
        "        self.current_step += 1\n",
        "\n",
        "        # Check if max length reached\n",
        "        if self.current_step >= self.max_len:\n",
        "            self.done = True\n",
        "\n",
        "        # Calculate reward\n",
        "        reward = self._calculate_reward()\n",
        "\n",
        "        # Get next state\n",
        "        next_state = self._get_state()\n",
        "\n",
        "        return next_state, reward, self.done, False, {}\n",
        "\n",
        "    def _get_state(self):\n",
        "        \"\"\"Get enhanced state representation.\"\"\"\n",
        "        # Encode dhatu with one-hot encoding\n",
        "        dhatu = self.current_sample[\"dhatu\"]\n",
        "        dhatu_encoded = [0] * 128  # Unicode range for Devanagari\n",
        "        for c in dhatu:\n",
        "            if ord(c) < 128:\n",
        "                dhatu_encoded[ord(c)] = 1\n",
        "\n",
        "        # One-hot encode grammatical features\n",
        "        gana_vec = [0] * len(self.ganas)\n",
        "        gana_vec[self.gana_to_idx[self.current_sample[\"gana\"]]] = 1\n",
        "\n",
        "        pada_vec = [0] * len(self.padas)\n",
        "        pada_vec[self.pada_to_idx[self.current_sample[\"pada\"]]] = 1\n",
        "\n",
        "        lakara_vec = [0] * len(self.lakaras)\n",
        "        lakara_vec[self.lakara_to_idx[self.current_sample[\"lakara\"]]] = 1\n",
        "\n",
        "        purusha_vec = [0] * len(self.purushas)\n",
        "        purusha_vec[self.purusha_to_idx[self.current_sample[\"purusha\"]]] = 1\n",
        "\n",
        "        vacana_vec = [0] * len(self.vacanas)\n",
        "        vacana_vec[self.vacana_to_idx[self.current_sample[\"vacana\"]]] = 1\n",
        "\n",
        "        # Encode current output with positional awareness\n",
        "        output_encoded = []\n",
        "        for i, c in enumerate(self.current_output):\n",
        "            if c in self.char_to_idx:\n",
        "                # Add position information\n",
        "                pos_encoded = [0] * len(self.char_to_idx)\n",
        "                pos_encoded[self.char_to_idx[c]] = 1\n",
        "                output_encoded.extend(pos_encoded)\n",
        "            if i >= 4:  # Limit to first 5 characters to keep state size reasonable\n",
        "                break\n",
        "\n",
        "        # Pad if needed\n",
        "        output_encoded = output_encoded + [0] * (5 * len(self.char_to_idx) - len(output_encoded))\n",
        "\n",
        "        # Combine all features\n",
        "        state = dhatu_encoded + gana_vec + pada_vec + lakara_vec + purusha_vec + vacana_vec + output_encoded\n",
        "        return state\n",
        "\n",
        "    def _calculate_reward(self):\n",
        "        \"\"\"Calculate a more informative reward based on character-level matching.\"\"\"\n",
        "        if not self.done:\n",
        "            return 0  # No intermediate rewards\n",
        "\n",
        "        # Get expected form\n",
        "        expected = self.current_sample[\"surface_form\"]\n",
        "        predicted = self.current_output\n",
        "\n",
        "        # Perfect match gets highest reward\n",
        "        if predicted == expected:\n",
        "            return 10.0\n",
        "\n",
        "        # Character-level matching with position awareness\n",
        "        match_score = 0\n",
        "        for i, (p, e) in enumerate(zip(predicted, expected)):\n",
        "            if p == e:\n",
        "                # Reward early correct matches more highly\n",
        "                position_weight = 1.0 - (i / len(expected) * 0.5) if len(expected) > 0 else 0\n",
        "                match_score += position_weight\n",
        "\n",
        "        # Penalize length differences\n",
        "        length_penalty = abs(len(predicted) - len(expected)) * 0.2\n",
        "\n",
        "        # Reward for stem correctness (first part of the word)\n",
        "        stem_length = min(3, len(expected)//2)\n",
        "        if len(predicted) >= stem_length and predicted[:stem_length] == expected[:stem_length]:\n",
        "            match_score += 2.0\n",
        "\n",
        "        # Calculate final reward\n",
        "        reward = match_score - length_penalty\n",
        "\n",
        "        # Scale between -1 and 10\n",
        "        return max(-1.0, min(10.0, reward))\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, action_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return F.softmax(x, dim=1)\n",
        "\n",
        "\n",
        "class ReinforceAgent:\n",
        "    def __init__(self, state_dim, action_dim, lr=0.001, gamma=0.99):\n",
        "        self.state_dim = state_dim\n",
        "        self.action_dim = action_dim\n",
        "        self.gamma = gamma  # Discount factor for future rewards\n",
        "\n",
        "        # Initialize policy network\n",
        "        self.policy_net = PolicyNetwork(state_dim, action_dim)\n",
        "\n",
        "        # Optimizer\n",
        "        self.optimizer = torch.optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "\n",
        "        # Memory for storing experiences\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.log_probs = []\n",
        "        self.dones = []\n",
        "\n",
        "    def select_action(self, state):\n",
        "        \"\"\"Select an action based on the current policy.\"\"\"\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0)  # Add batch dimension\n",
        "        action_probs = self.policy_net(state_tensor)\n",
        "        dist = Categorical(action_probs)\n",
        "        action = dist.sample()\n",
        "        log_prob = dist.log_prob(action)\n",
        "\n",
        "        # Store in memory\n",
        "        self.states.append(state.squeeze(0))  # Remove batch dimension for storage\n",
        "        self.actions.append(action)\n",
        "        self.log_probs.append(log_prob)\n",
        "\n",
        "        return action.item()\n",
        "\n",
        "    def store_outcome(self, reward, done):\n",
        "        \"\"\"Store reward and done flag from the environment.\"\"\"\n",
        "        self.rewards.append(reward)\n",
        "        self.dones.append(done)\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"Update policy using REINFORCE.\"\"\"\n",
        "        if len(self.states) == 0:\n",
        "            return 0.0  # Return 0 loss if no experiences\n",
        "\n",
        "        # Calculate discounted rewards\n",
        "        discounted_rewards = []\n",
        "        R = 0\n",
        "        for reward, done in zip(reversed(self.rewards), reversed(self.dones)):\n",
        "            if done:\n",
        "                R = 0\n",
        "            R = reward + self.gamma * R\n",
        "            discounted_rewards.insert(0, R)\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        states = torch.stack(self.states)\n",
        "        log_probs = torch.stack(self.log_probs)\n",
        "        rewards = torch.FloatTensor(discounted_rewards)\n",
        "\n",
        "        # Normalize rewards\n",
        "        if len(rewards) > 1:\n",
        "            rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n",
        "\n",
        "        # Calculate loss\n",
        "        policy_loss = -(log_probs * rewards).sum()\n",
        "\n",
        "        # Update network\n",
        "        self.optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Store the loss value before clearing memory\n",
        "        loss_value = policy_loss.item()\n",
        "\n",
        "        # Clear memory\n",
        "        self.clear_memory()\n",
        "\n",
        "        return loss_value\n",
        "\n",
        "    def clear_memory(self):\n",
        "        \"\"\"Clear agent's memory after update.\"\"\"\n",
        "        self.states = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.log_probs = []\n",
        "        self.dones = []\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"Save model weights.\"\"\"\n",
        "        torch.save(self.policy_net.state_dict(), path)\n",
        "\n",
        "    def load(self, path):\n",
        "        \"\"\"Load model weights.\"\"\"\n",
        "        self.policy_net.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "lbee0UvEK2bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avWwSgQ6i6D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ydP0NRh5fP68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1_nmpfsaVe3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QwenSanskritEnhancer:\n",
        "    \"\"\"Uses Qwen model to enhance Sanskrit processing capabilities.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name=\"Qwen/Qwen1.5-0.5B\"):\n",
        "        print(f\"Loading Qwen model: {model_name}\")\n",
        "        try:\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True)\n",
        "            self.model_loaded = True\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading Qwen model: {e}\")\n",
        "            print(\"Continuing without Qwen model.\")\n",
        "            self.model_loaded = False\n",
        "\n",
        "    def explain_panini_rule(self, dhatu, morphological_params):\n",
        "        \"\"\"Explain the Paninian grammar rule being applied.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return \"Qwen model not available for explanation.\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Explain the Paninian grammar rule that transforms the Sanskrit root (dhatu) \"{dhatu}\"\n",
        "        with the following morphological parameters:\n",
        "        - Gana (verb class): {morphological_params['gana']}\n",
        "        - Pada (voice): {morphological_params['pada']}\n",
        "        - Lakara (tense/mood): {morphological_params['lakara']}\n",
        "        - Purusha (person): {morphological_params['purusha']}\n",
        "        - Vacana (number): {morphological_params['vacana']}\n",
        "\n",
        "        Explain step by step how these parameters affect the final surface form according to Panini's Ashtadhyayi.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=250,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            explanation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the generated part (removing the prompt)\n",
        "            explanation = explanation[len(prompt):]\n",
        "\n",
        "            return explanation.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error generating explanation: {e}\"\n",
        "\n",
        "    def verify_form_with_reasoning(self, predicted, expected, params):\n",
        "        \"\"\"Verify the form with LLM-based reasoning about correctness.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return None\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        In Sanskrit morphology, the verbal root (dhatu) \"{params['dhatu']}\" with parameters:\n",
        "        - Gana: {params['gana']}\n",
        "        - Pada: {params['pada']}\n",
        "        - Lakara: {params['lakara']}\n",
        "        - Purusha: {params['purusha']}\n",
        "        - Vacana: {params['vacana']}\n",
        "\n",
        "        should transform to: {expected}\n",
        "\n",
        "        The model generated: {predicted}\n",
        "\n",
        "        Analyze if the generated form is correct. If not, explain what specific Paninian rule was violated\n",
        "        and how the transformation should have proceeded.\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=300,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            analysis = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the generated part\n",
        "            analysis = analysis[len(prompt):]\n",
        "\n",
        "            return analysis.strip()\n",
        "        except Exception as e:\n",
        "            return f\"Error generating analysis: {e}\"\n",
        "\n",
        "    def translate_english_to_sanskrit(self, english_text, morphological_context=None):\n",
        "        \"\"\"Translate English to Sanskrit with morphological awareness.\"\"\"\n",
        "        if not self.model_loaded:\n",
        "            return \"Qwen model not available for translation.\"\n",
        "\n",
        "        if morphological_context:\n",
        "            context = f\"\"\"\n",
        "            - Grammatical context: {morphological_context['gana']} verb class,\n",
        "            {morphological_context['pada']} voice, {morphological_context['lakara']} tense,\n",
        "            {morphological_context['purusha']} person, {morphological_context['vacana']} number\n",
        "            \"\"\"\n",
        "        else:\n",
        "            context = \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Translate the following English text to Sanskrit using Devanagari script.\n",
        "        {context}\n",
        "\n",
        "        English: {english_text}\n",
        "        Sanskrit:\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=100,\n",
        "                temperature=0.7,\n",
        "                do_sample=True\n",
        "            )\n",
        "            translation = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract only the translation\n",
        "            if \"Sanskrit:\" in translation:\n",
        "                translation = translation.split(\"Sanskrit:\")[1].strip()\n",
        "\n",
        "            return translation\n",
        "        except Exception as e:\n",
        "            return f\"Error generating translation: {e}\""
      ],
      "metadata": {
        "id": "PAoZJUavK2eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "roFgwZjILf6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def supervised_pretraining(model, dataset, char_to_idx, idx_to_char, epochs=30, batch_size=32):\n",
        "    \"\"\"Pre-train the policy network using supervised learning.\"\"\"\n",
        "    print(\"Starting supervised pre-training...\")\n",
        "\n",
        "    # Create optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Create environment to use its encoding functions\n",
        "    env = SanskritMorphologyEnv(dataset)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        num_batches = 0\n",
        "\n",
        "        # Shuffle data each epoch\n",
        "        indices = torch.randperm(len(dataset))\n",
        "\n",
        "        for start_idx in range(0, len(dataset), batch_size):\n",
        "            end_idx = min(start_idx + batch_size, len(dataset))\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            batch_states = []\n",
        "            batch_targets = []\n",
        "\n",
        "            # Prepare batch data\n",
        "            for idx in batch_indices:\n",
        "                item = dataset[idx]\n",
        "\n",
        "                # Set current sample in environment\n",
        "                env.current_sample = item\n",
        "                env.current_output = \"\"\n",
        "\n",
        "                # Get initial state\n",
        "                state = env._get_state()\n",
        "                batch_states.append(state)\n",
        "\n",
        "                # Get target (expected surface form)\n",
        "                expected = item[\"surface_form\"]\n",
        "                if len(expected) > 0:\n",
        "                    target_char = expected[0]\n",
        "                    target_idx = char_to_idx.get(target_char, 0)\n",
        "                    batch_targets.append(target_idx)\n",
        "                else:\n",
        "                    batch_targets.append(0)\n",
        "\n",
        "            # Convert to tensors\n",
        "            batch_states = torch.FloatTensor(batch_states)\n",
        "            batch_targets = torch.tensor(batch_targets, dtype=torch.long)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(batch_states)\n",
        "\n",
        "            # Calculate loss\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            loss = criterion(outputs, batch_targets)\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/max(1, num_batches):.4f}\")\n",
        "\n",
        "    print(\"Supervised pre-training completed!\")\n",
        "    return model\n",
        "\n",
        "def train_agent(env, agent, num_episodes=300, max_steps=30, update_freq=20):\n",
        "    \"\"\"Train the agent.\"\"\"\n",
        "    episode_rewards = []\n",
        "    accuracy_history = []\n",
        "\n",
        "    progress_bar = tqdm(range(num_episodes), desc=\"Training\")\n",
        "\n",
        "    for episode in progress_bar:\n",
        "        state, _ = env.reset()\n",
        "        episode_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            action = agent.select_action(state)\n",
        "            next_state, reward, done, _, _ = env.step(action)\n",
        "\n",
        "            agent.store_outcome(reward, done)\n",
        "            episode_reward += reward\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "            state = next_state\n",
        "\n",
        "        # Update agent\n",
        "        if (episode + 1) % update_freq == 0:\n",
        "            agent.update()\n",
        "\n",
        "        episode_rewards.append(episode_reward)\n",
        "\n",
        "        # Calculate and track accuracy periodically\n",
        "        if (episode + 1) % 50 == 0:\n",
        "            # Evaluate on a small subset\n",
        "            eval_accuracy = evaluate_accuracy(env, agent, num_samples=20)\n",
        "            accuracy_history.append(eval_accuracy)\n",
        "\n",
        "            progress_bar.set_postfix({\n",
        "                'reward': f'{episode_reward:.2f}',\n",
        "                'accuracy': f'{eval_accuracy:.2f}'\n",
        "            })\n",
        "\n",
        "    return episode_rewards, accuracy_history\n",
        "\n",
        "def evaluate_accuracy(env, agent, num_samples=20):\n",
        "    \"\"\"Evaluate model accuracy on a subset of examples.\"\"\"\n",
        "    correct = 0\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        state, _ = env.reset()\n",
        "        env.done = False\n",
        "\n",
        "        while not env.done:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state)\n",
        "                action_probs = agent.policy_net(state_tensor)\n",
        "                action = torch.argmax(action_probs).item()\n",
        "\n",
        "            state, _, done, _, _ = env.step(action)\n",
        "            if env.current_step >= env.max_len:\n",
        "                break\n",
        "\n",
        "        verification = env.verifier.verify_form(env.current_output, env.current_sample)\n",
        "        if verification[\"is_correct\"]:\n",
        "            correct += 1\n",
        "\n",
        "    return correct / num_samples\n",
        "\n",
        "\n",
        "\n",
        "def create_curriculum_env(original_env, dataset):\n",
        "    \"\"\"Create a new environment with the same character mappings as the original.\"\"\"\n",
        "    new_env = SanskritMorphologyEnv(dataset)\n",
        "\n",
        "    # Replace the character mappings with the original ones\n",
        "    new_env.char_to_idx = original_env.char_to_idx\n",
        "    new_env.idx_to_char = original_env.idx_to_char\n",
        "\n",
        "    return new_env\n",
        "\n",
        "def curriculum_training(original_env, agent, full_dataset, generator, episodes_per_level=100):\n",
        "    \"\"\"Train the agent using a curriculum that gradually increases difficulty.\"\"\"\n",
        "    rewards_history = []\n",
        "    accuracy_history = []\n",
        "\n",
        "    # Level 1: Single dhatu, single tense, fixed person/number\n",
        "    print(\"\\nCurriculum Level 1: Single dhatu (भू), present tense, 3rd person singular\")\n",
        "    level1_data = [item for item in full_dataset if\n",
        "                   item[\"dhatu\"] == \"भू\" and\n",
        "                   item[\"lakara\"] == \"लट्\" and\n",
        "                   item[\"purusha\"] == \"प्रथम\" and\n",
        "                   item[\"vacana\"] == \"एकवचन\"]\n",
        "\n",
        "    # Generate more if needed\n",
        "    if len(level1_data) < 50:\n",
        "        while len(level1_data) < 50:\n",
        "            more_items = generator.generate_dataset(50)\n",
        "            filtered_items = [item for item in more_items if\n",
        "                              item[\"dhatu\"] == \"भू\" and\n",
        "                              item[\"lakara\"] == \"लट्\" and\n",
        "                              item[\"purusha\"] == \"प्रथम\" and\n",
        "                              item[\"vacana\"] == \"एकवचन\"]\n",
        "            level1_data.extend(filtered_items)\n",
        "\n",
        "    # Create environment with consistent dimensions\n",
        "    env = create_curriculum_env(original_env, level1_data)\n",
        "\n",
        "    # Train on level 1\n",
        "    rewards1, accuracies1 = train_agent(env, agent, num_episodes=episodes_per_level)\n",
        "    rewards_history.extend(rewards1)\n",
        "    accuracy_history.extend(accuracies1)\n",
        "\n",
        "    # Level 2: Multiple dhatus, present tense only\n",
        "    print(\"\\nCurriculum Level 2: Multiple dhatus, present tense only\")\n",
        "    level2_data = [item for item in full_dataset if item[\"lakara\"] == \"लट्\"]\n",
        "\n",
        "    # Update environment with consistent dimensions\n",
        "    env = create_curriculum_env(original_env, level2_data)\n",
        "\n",
        "    # Train on level 2\n",
        "    rewards2, accuracies2 = train_agent(env, agent, num_episodes=episodes_per_level)\n",
        "    rewards_history.extend(rewards2)\n",
        "    accuracy_history.extend(accuracies2)\n",
        "\n",
        "    # Level 3: Full dataset\n",
        "    print(\"\\nCurriculum Level 3: Full complexity\")\n",
        "    env = create_curriculum_env(original_env, full_dataset)\n",
        "\n",
        "    # Train on level 3\n",
        "    rewards3, accuracies3 = train_agent(env, agent, num_episodes=episodes_per_level)\n",
        "    rewards_history.extend(rewards3)\n",
        "    accuracy_history.extend(accuracies3)\n",
        "\n",
        "    return rewards_history, accuracy_history, env"
      ],
      "metadata": {
        "id": "MaDCL2Z8Lf88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-wcleQELgAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # 1. Generate dataset\n",
        "        print(\"Generating Sanskrit dataset...\")\n",
        "        generator = SanskritDataGenerator()\n",
        "        full_dataset = generator.generate_dataset(1000)\n",
        "\n",
        "        # Simplify the dataset\n",
        "        print(\"Simplifying dataset for easier learning...\")\n",
        "        simplified_dataset = filter_dataset(full_dataset, \"लट्\", \"परस्मैपद\")\n",
        "        while len(simplified_dataset) < 100:\n",
        "            more_items = generator.generate_dataset(100)\n",
        "            simplified_items = filter_dataset(more_items, \"लट्\", \"परस्मैपद\")\n",
        "            simplified_dataset.extend(simplified_items)\n",
        "\n",
        "        dataset = simplified_dataset[:500]\n",
        "        print(f\"Using simplified dataset with {len(dataset)} examples\")\n",
        "\n",
        "        # Split dataset\n",
        "        train_data, val_data, test_data = split_dataset(dataset)\n",
        "\n",
        "        # 2. Create RL environment\n",
        "        print(\"Setting up RL environment...\")\n",
        "        env = SanskritMorphologyEnv(train_data)\n",
        "        # Calculate state dimensions by getting an actual state from the environment\n",
        "        initial_state, _ = env.reset()\n",
        "        state_dim = len(initial_state)  # Get actual state dimension\n",
        "        action_dim = env.action_space\n",
        "\n",
        "        # This line should be indented to be inside the try block\n",
        "        print(f\"State dimension: {state_dim}, Action dimension: {action_dim}\")\n",
        "\n",
        "        # Continue with the rest of your code...\n",
        "\n",
        "\n",
        "\n",
        "        # 3. Initialize Qwen enhancer\n",
        "        print(\"Initializing Qwen model for enhanced capabilities...\")\n",
        "        qwen_enhancer = QwenSanskritEnhancer()\n",
        "\n",
        "        # 4. Create RL agent\n",
        "        print(\"Creating RL agent for Sanskrit morphology...\")\n",
        "        agent = ReinforceAgent(state_dim, action_dim)\n",
        "\n",
        "        # 5. Pre-train the agent's policy network\n",
        "        print(\"Starting supervised pre-training...\")\n",
        "        agent.policy_net = supervised_pretraining(\n",
        "            agent.policy_net,\n",
        "            train_data,\n",
        "            env.char_to_idx,\n",
        "            env.idx_to_char,\n",
        "            epochs=30\n",
        "        )\n",
        "\n",
        "        # 6. Train with curriculum learning\n",
        "        print(\"Training RL agent with curriculum learning...\")\n",
        "        rewards, accuracies, final_env = curriculum_training(\n",
        "            env,\n",
        "            agent,\n",
        "            full_dataset,\n",
        "            generator,\n",
        "            episodes_per_level=100\n",
        "        )\n",
        "\n",
        "        # Save the trained model\n",
        "        agent.save(\"sanskrit_morphology_model.pt\")\n",
        "\n",
        "        # 7. Evaluate on test data\n",
        "        print(\"Evaluating on test data...\")\n",
        "        test_accuracy = evaluate_accuracy(env, agent, num_samples=50)\n",
        "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "        # 8. Generate examples with LLM explanations\n",
        "        print(\"\\nGenerating examples with explanations:\")\n",
        "        samples = random.sample(test_data, 5)\n",
        "        results = generate_examples_with_explanations(samples, env, agent, qwen_enhancer)\n",
        "\n",
        "        # 9. English to Sanskrit translation\n",
        "        print(\"\\nDemonstrating English to Sanskrit translation with morphological awareness:\")\n",
        "        translation_examples = generate_translation_examples(samples, qwen_enhancer)\n",
        "\n",
        "        # 10. Plot results\n",
        "        plot_results(rewards, accuracies)\n",
        "\n",
        "        # 11. Save results\n",
        "        output = {\n",
        "            \"test_accuracy\": test_accuracy,\n",
        "            \"examples\": results,\n",
        "            \"translation_examples\": translation_examples,\n",
        "            \"training\": {\n",
        "                \"rewards\": rewards,\n",
        "                \"accuracies\": accuracies\n",
        "            }\n",
        "        }\n",
        "        save_results(output)\n",
        "\n",
        "        # Print research question conclusion\n",
        "        print_research_conclusion(test_accuracy)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "def filter_dataset(dataset, lakara, pada):\n",
        "    return [item for item in dataset if item[\"lakara\"] == lakara and item[\"pada\"] == pada]\n",
        "\n",
        "def split_dataset(dataset):\n",
        "    random.shuffle(dataset)\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    train_data = dataset[:train_size]\n",
        "    val_data = dataset[train_size:train_size+val_size]\n",
        "    test_data = dataset[train_size+val_size:]\n",
        "    return train_data, val_data, test_data\n",
        "\n",
        "def get_environment_dimensions(env):\n",
        "    dhatu_dim = 128\n",
        "    grammar_dim = len(env.ganas) + len(env.padas) + len(env.lakaras) + len(env.purushas) + len(env.vacanas)\n",
        "    output_dim = 5 * len(env.char_to_idx)\n",
        "    state_dim = dhatu_dim + grammar_dim + output_dim\n",
        "    action_dim = env.action_space\n",
        "    return state_dim, action_dim\n",
        "\n",
        "def generate_examples_with_explanations(samples, env, agent, qwen_enhancer):\n",
        "    results = []\n",
        "    for sample in samples:\n",
        "        # Generate form using trained policy\n",
        "        env.current_sample = sample\n",
        "        env.current_output = \"\"\n",
        "        env.current_step = 0\n",
        "        env.done = False\n",
        "        state = env._get_state()\n",
        "\n",
        "        while not env.done:\n",
        "            with torch.no_grad():\n",
        "                state_tensor = torch.FloatTensor(state)\n",
        "                action_probs = agent.policy_net(state_tensor)\n",
        "                action = torch.argmax(action_probs).item()\n",
        "\n",
        "            state, _, done, _, _ = env.step(action)\n",
        "            if env.current_step >= env.max_len:\n",
        "                break\n",
        "\n",
        "        # Get verification\n",
        "        verification = env.verifier.verify_form(env.current_output, sample)\n",
        "\n",
        "        # Get Qwen explanation if available\n",
        "        panini_explanation = qwen_enhancer.explain_panini_rule(sample[\"dhatu\"], sample)\n",
        "        verification_reasoning = qwen_enhancer.verify_form_with_reasoning(\n",
        "            env.current_output, verification[\"expected\"], sample)\n",
        "\n",
        "        # Store results\n",
        "        result = {\n",
        "            \"dhatu\": sample[\"dhatu\"],\n",
        "            \"parameters\": {\n",
        "                \"gana\": sample[\"gana\"],\n",
        "                \"pada\": sample[\"pada\"],\n",
        "                \"lakara\": sample[\"lakara\"],\n",
        "                \"purusha\": sample[\"purusha\"],\n",
        "                \"vacana\": sample[\"vacana\"]\n",
        "            },\n",
        "            \"english\": sample[\"english\"],\n",
        "            \"expected\": verification[\"expected\"],\n",
        "            \"generated\": env.current_output,\n",
        "            \"is_correct\": verification[\"is_correct\"],\n",
        "            \"accuracy\": verification[\"accuracy\"],\n",
        "            \"panini_explanation\": panini_explanation,\n",
        "            \"verification_reasoning\": verification_reasoning\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        # Print example\n",
        "        print_example(result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def generate_translation_examples(samples, qwen_enhancer):\n",
        "    translation_examples = []\n",
        "    for sample in samples[:3]:\n",
        "        english_text = sample[\"english\"]\n",
        "        morphological_context = {\n",
        "            \"gana\": sample[\"gana\"],\n",
        "            \"pada\": sample[\"pada\"],\n",
        "            \"lakara\": sample[\"lakara\"],\n",
        "            \"purusha\": sample[\"purusha\"],\n",
        "            \"vacana\": sample[\"vacana\"]\n",
        "        }\n",
        "\n",
        "        # Translate with morphological context\n",
        "        translation = qwen_enhancer.translate_english_to_sanskrit(english_text, morphological_context)\n",
        "\n",
        "        print_translation_example(english_text, morphological_context, translation, sample)\n",
        "        translation_examples.append({\n",
        "            \"english\": english_text,\n",
        "            \"context\": morphological_context,\n",
        "            \"translation\": translation,\n",
        "            \"expected\": sample[\"surface_form\"]\n",
        "        })\n",
        "\n",
        "    return translation_examples\n",
        "\n",
        "def plot_results(rewards, accuracies):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(rewards)\n",
        "    plt.title('RL Training Rewards')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(range(0, len(accuracies)*50, 50), accuracies)\n",
        "    plt.title('Morphology Accuracy')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Accuracy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sanskrit_morphology_results.png')\n",
        "    plt.show()\n",
        "\n",
        "def save_results(output):\n",
        "    with open(\"sanskrit_results.json\", \"w\") as f:\n",
        "        json.dump(output, f, indent=2)\n",
        "\n",
        "def print_research_conclusion(test_accuracy):\n",
        "    print(\"\\nResearch Question: Will learning Paninian grammar rules improve English→Sanskrit translation?\")\n",
        "    print(f\"\\nBased on our model achieving {test_accuracy:.2%} accuracy in generating correct Sanskrit forms,\")\n",
        "    print(\"we can conclude that a computational approach to Paninian grammar is feasible.\")\n",
        "    print(\"The integration of the Qwen model provides enhanced capabilities for:\")\n",
        "    print(\"1. Explaining the Paninian rules being applied\")\n",
        "    print(\"2. Verifying and reasoning about morphological transformations\")\n",
        "    print(\"3. Improving English→Sanskrit translation with morphological awareness\")\n",
        "\n",
        "    print(\"\\nThese results suggest that incorporating Paninian grammar knowledge into\")\n",
        "    print(\"translation systems would improve English→Sanskrit translation quality,\")\n",
        "    print(\"especially for grammatical correctness and morphological accuracy.\")\n",
        "\n",
        "def print_example(result):\n",
        "    print(f\"\\nDhatu: {result['dhatu']}\")\n",
        "    print(f\"Parameters: {result['parameters']['gana']}, {result['parameters']['pada']}, {result['parameters']['lakara']}, \"\n",
        "          f\"{result['parameters']['purusha']}, {result['parameters']['vacana']}\")\n",
        "    print(f\"English meaning: {result['english']}\")\n",
        "    print(f\"Expected form: {result['expected']}\")\n",
        "    print(f\"Generated form: {result['generated']}\")\n",
        "    print(f\"Correct: {'Yes' if result['is_correct'] else 'No'}\")\n",
        "\n",
        "    if result['verification_reasoning']:\n",
        "        print(\"\\nVerification reasoning:\")\n",
        "        print(result['verification_reasoning'][:200] + \"...\" if len(result['verification_reasoning']) > 200 else result['verification_reasoning'])\n",
        "\n",
        "    print(\"--------------------\")\n",
        "\n",
        "def print_translation_example(english_text, morphological_context, translation, sample):\n",
        "    print(f\"\\nEnglish: {english_text}\")\n",
        "    print(f\"Context: {morphological_context['gana']} verb, {morphological_context['lakara']} tense, {morphological_context['purusha']} person\")\n",
        "    print(f\"Translation: {translation}\")\n",
        "    print(f\"Expected verb form: {sample['surface_form']}\")\n",
        "    print(\"--------------------\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLvdofGpLkus",
        "outputId": "0a600e40-df1d-45ee-b608-8c4acbeb966d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Sanskrit dataset...\n",
            "Simplifying dataset for easier learning...\n",
            "Using simplified dataset with 100 examples\n",
            "Setting up RL environment...\n",
            "State dimension: 296, Action dimension: 31\n",
            "Initializing Qwen model for enhanced capabilities...\n",
            "Loading Qwen model: Qwen/Qwen1.5-0.5B\n",
            "Creating RL agent for Sanskrit morphology...\n",
            "Starting supervised pre-training...\n",
            "Starting supervised pre-training...\n",
            "Epoch 1/30, Loss: 3.4339\n",
            "Epoch 2/30, Loss: 3.4331\n",
            "Epoch 3/30, Loss: 3.4324\n",
            "Epoch 4/30, Loss: 3.4318\n",
            "Epoch 5/30, Loss: 3.4307\n",
            "Epoch 6/30, Loss: 3.4293\n",
            "Epoch 7/30, Loss: 3.4283\n",
            "Epoch 8/30, Loss: 3.4245\n",
            "Epoch 9/30, Loss: 3.4210\n",
            "Epoch 10/30, Loss: 3.4163\n",
            "Epoch 11/30, Loss: 3.4138\n",
            "Epoch 12/30, Loss: 3.4031\n",
            "Epoch 13/30, Loss: 3.3965\n",
            "Epoch 14/30, Loss: 3.3915\n",
            "Epoch 15/30, Loss: 3.3782\n",
            "Epoch 16/30, Loss: 3.3730\n",
            "Epoch 17/30, Loss: 3.3473\n",
            "Epoch 18/30, Loss: 3.3448\n",
            "Epoch 19/30, Loss: 3.3558\n",
            "Epoch 20/30, Loss: 3.3864\n",
            "Epoch 21/30, Loss: 3.3815\n",
            "Epoch 22/30, Loss: 3.3084\n",
            "Epoch 23/30, Loss: 3.3051\n",
            "Epoch 24/30, Loss: 3.3666\n",
            "Epoch 25/30, Loss: 3.3444\n",
            "Epoch 26/30, Loss: 3.3487\n",
            "Epoch 27/30, Loss: 3.3780\n",
            "Epoch 28/30, Loss: 3.2766\n",
            "Epoch 29/30, Loss: 3.3591\n",
            "Epoch 30/30, Loss: 3.3290\n",
            "Supervised pre-training completed!\n",
            "Training RL agent with curriculum learning...\n",
            "\n",
            "Curriculum Level 1: Single dhatu (भू), present tense, 3rd person singular\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: mat1 and mat2 shapes cannot be multiplied (1x294 and 296x128)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-102-ef780a2e403d>\", line 62, in main\n",
            "    rewards, accuracies, final_env = curriculum_training(\n",
            "                                     ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-98-51b3b970049b>\", line 177, in curriculum_training\n",
            "    rewards1, accuracies1 = train_agent(env, agent, num_episodes=episodes_per_level)\n",
            "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-98-51b3b970049b>\", line 83, in train_agent\n",
            "    action = agent.select_action(state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-96-e80ad3fc25e1>\", line 369, in select_action\n",
            "    action_probs = self.policy_net(state_tensor)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<ipython-input-96-e80ad3fc25e1>\", line 341, in forward\n",
            "    x = F.relu(self.fc1(x))\n",
            "               ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x294 and 296x128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwMjDPpzjnF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "15owChzVjEaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gDkZN5zZMS0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D5jIDbBHMS3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cdx5wjdMtNLy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}